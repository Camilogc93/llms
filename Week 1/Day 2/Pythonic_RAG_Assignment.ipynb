{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lElF3o5PR6ys"
      },
      "source": [
        "# Your First RAG Application\n",
        "\n",
        "In this notebook, we'll walk you through each of the components that are involved in a simple RAG application.\n",
        "\n",
        "We won't be leveraging any fancy tools, just the OpenAI Python SDK, Numpy, and some classic Python.\n",
        "\n",
        "> NOTE: This was done with Python 3.11.4.\n",
        "\n",
        "> NOTE: There might be [compatibility issues](https://github.com/wandb/wandb/issues/7683) if you're on NVIDIA driver >552.44 As an interim solution - you can rollback your drivers to the 552.44."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CtcL8P8R6yt"
      },
      "source": [
        "## Table of Contents:\n",
        "\n",
        "- Task 1: Imports and Utilities\n",
        "- Task 2: Documents\n",
        "- Task 3: Embeddings and Vectors\n",
        "- Task 4: Prompts\n",
        "- Task 5: Retrieval Augmented Generation\n",
        "  - üöß Activity #1: Augment RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dz6GYilR6yt"
      },
      "source": [
        "Let's look at a rather complicated looking visual representation of a basic RAG application.\n",
        "\n",
        "<img src=\"https://i.imgur.com/vD8b016.png\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjmC0KFtR6yt"
      },
      "source": [
        "## Task 1: Imports and Utility\n",
        "\n",
        "We're just doing some imports and enabling `async` to work within the Jupyter environment here, nothing too crazy!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7VEzqziR6yt",
        "outputId": "f873dd3b-55a0-4e00-ecf4-e2a0fe3af327"
      },
      "outputs": [],
      "source": [
        "!pip install -qU numpy matplotlib plotly pandas scipy scikit-learn openai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z1dyrG4hR6yt"
      },
      "outputs": [],
      "source": [
        "from aimakerspace.text_utils import TextFileLoader, CharacterTextSplitter,PdFileLoader\n",
        "from aimakerspace.vectordatabase import VectorDatabase\n",
        "import asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9OrFZRnER6yt"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0jGnpQsR6yu"
      },
      "source": [
        "## Task 2: Documents\n",
        "\n",
        "We'll be concerning ourselves with this part of the flow in the following section:\n",
        "\n",
        "<img src=\"https://i.imgur.com/jTm9gjk.png\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SFPWvRUR6yu"
      },
      "source": [
        "### Loading Source Documents\n",
        "\n",
        "So, first things first, we need some documents to work with.\n",
        "\n",
        "While we could work directly with the `.txt` files (or whatever file-types you wanted to extend this to) we can instead do some batch processing of those documents at the beginning in order to store them in a more machine compatible format.\n",
        "\n",
        "In this case, we're going to parse our text file into a single document in memory.\n",
        "\n",
        "Let's look at the relevant bits of the `TextFileLoader` class:\n",
        "\n",
        "```python\n",
        "def load_file(self):\n",
        "        with open(self.path, \"r\", encoding=self.encoding) as f:\n",
        "            self.documents.append(f.read())\n",
        "```\n",
        "\n",
        "We're simply loading the document using the built in `open` method, and storing that output in our `self.documents` list.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia2sUEuGR6yu",
        "outputId": "84937ecc-c35f-4c4a-a4ab-9da72625954c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf_loader = PdFileLoader(\"data/agent_paper.pdf\")\n",
        "documents = pdf_loader.load_documents()\n",
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['2024-8-19\\nAutomated Design of Agentic Systems\\nShengran Hu1,2, Cong Lu1,2and Jeff Clune1,2,3\\n1University of British Columbia,2Vector Institute,3Canada CIFAR AI Chair\\nResearchers are investing substantial effort in developing powerful general-purpose agents, wherein\\nFoundation Models are used as modules within agentic systems (e.g. Chain-of-Thought, Self-Reflection,\\nToolformer). However, the history of machine learning teaches us that hand-designed solutions are\\neventually replaced by learned solutions. We formulate a new research area, Automated Design of\\nAgentic Systems (ADAS), which aims to automatically create powerful agentic system designs, including\\ninventing novel building blocks and/or combining them in new ways. We further demonstrate that there\\nis an unexplored yet promising approach within ADAS where agents can be defined in code and new\\nagents can be automatically discovered by a meta agent programming ever better ones in code. Given\\nthat programming languages are Turing Complete, this approach theoretically enables the learning\\nofany possible agentic system: including novel prompts, tool use, control flows, and combinations\\nthereof. We present a simple yet effective algorithm named Meta Agent Search to demonstrate this idea,\\nwhere a meta agent iteratively programs interesting new agents based on an ever-growing archive of\\nprevious discoveries. Through extensive experiments across multiple domains including coding, science,\\nand math, we show that our algorithm can progressively invent agents with novel designs that greatly\\noutperform state-of-the-art hand-designed agents. Importantly, we consistently observe the surprising\\nresult that agents invented by Meta Agent Search maintain superior performance even when transferred\\nacross domains and models, demonstrating their robustness and generality. Provided we develop it\\nsafely, our work illustrates the potential of an exciting new research direction toward automatically\\ndesigning ever-more powerful agentic systems to benefit humanity.\\n/githubhttps://github.com/ShengranHu/ADAS\\n1. Introduction\\nFoundation Models (FMs) such as GPT (OpenAI, 2022, 2024) and Claude (Anthropic, 2024b) are\\nquicklybeingadoptedaspowerfulgeneral-purposeagentsforagentictasksthatneedflexiblereasoning\\nand planning (Wang et al., 2024). Despite recent advancements in FMs, solving problems reliably\\noften requires an agent to be a compound agentic system with multiple components instead of a\\nmonolithic model query (Rockt√§schel, 2024; Zaharia et al., 2024). Additionally, to enable agents to\\nsolve complex real-world tasks, they often need access to external tools such as search engines, code\\nexecution, and database queries. As a result, many effective building blocks of agentic systems have\\nbeen proposed, such as chain-of-thought planning and reasoning (Hu & Clune, 2024; Wei et al., 2022;\\nYao et al., 2023), memory structures (Lewis et al., 2020; Zhang et al., 2024c), tool use (Qu et al.,\\n2024; Schick et al., 2023), and self-reflection (Madaan et al., 2024; Shinn et al., 2023). Although\\nthese agents have already seen significant success across various applications (Wang et al., 2024),\\ndeveloping these building blocks and combining them into complex agentic systems often requires\\ndomain-specific manual tuning and substantial effort from both researchers and engineers.\\nHowever, the history of machine learning reveals a recurring theme: manually created arti-\\nfacts become replaced by learned, more efficient solutions over time as we get more compute and\\ndata (Clune, 2019). An early example is from computer vision, where hand-designed features like\\nHOG (Dalal & Triggs, 2005) were eventually replaced by learned features from Convolutional Neural\\nCorresponding author(s): Shengran Hu (srhu@cs.ubc.ca)arXiv:2408.08435v1  [cs.AI]  15 Aug 2024\\nAutomated Design of Agentic Systems\\nSummary and motivation : ‚ÄúBased on \\nthe insights from previous agents ‚Ä¶‚Äù,\\nName: ‚ÄúDivide and Conquer Agent‚Äù,\\nCode: ‚Äúdef forward(Task):\\n ‚Ä¶‚Ä¶\\n return Answer‚Äù\\nMeta AgentNext interesting agent\\nAgent ArchiveTest performance on tasks InputRefine until novel \\nand error -free\\nExamples of Discovered Agents\\nMulti -step Peer Review AgentExperts\\nAnswers\\nReviewersT ask\\nVerified Multimodal AgentT ask\\nVisual \\nParadigm\\nVerifier\\nVerified \\nParadigmVisual \\nAnalyzer\\nCOTAnswerT askSub -problem \\nDivision subsubsub\\nsubsub\\nExpertsAnswersEnsembleAnswer\\nDivide and Conquer AgentReviewsand add to archiveNew Agent\\n‚Ä¶\\nFigure 1|Overview of the proposed algorithm Meta Agent Search and examples of discovered\\nagents. In our algorithm, we instruct the ‚Äúmeta‚Äù agent to iteratively program new agents, test their\\nperformance on tasks, add them to an archive of discovered agents, and use this archive to inform the\\nmeta agent in subsequent iterations. We show three example agents across our runs, with all names\\ngenerated by the meta agent. The detailed code of example agents can be found in Appendix F.\\nNetworks (CNNs, Krizhevsky et al. (2012)). More recently, AutoML methods (Hutter et al., 2019)\\nand AI-Generating Algorithms (AI-GAs, Clune (2019)) have also demonstrated the superiority of\\nlearned AI systems compared to hand-designed AI systems. For example, the current best-performing\\nCNN models come from Neural Architecture Search (Elsken et al., 2019; Shen et al., 2023) instead\\nof manual design; in LLM alignment, learned loss functions (Lu et al., 2024a) outperform most\\nhand-designed ones such as DPO (Rafailov et al., 2024); The AI Scientist (Lu et al., 2024b) demon-\\nstrates an automated research pipeline, including the development of novel ML algorithms; and\\nan endless number of robotics learning environments can be automatically generated in works like\\nOMNI-EPIC (Faldor et al., 2024), which demonstrate surprising creativity in generated environments\\nand allow more efficient environment creation than the manual approach (see more examples in\\nSection 5). Therefore, in this paper, we propose a new research question: Can we automate the design\\nof agentic systems rather than relying on manual efforts?\\nTo explore the above research question, we formulate a new research area we call Automated\\nDesign of AgenticSystems (ADAS), which aims to automatically invent novel building blocks and\\ndesign powerful agentic systems (Section 2). We argue that ADAS may prove to be the fastest path to\\ndeveloping powerful agents, and show initial evidence that learned agents can greatly outperform\\nhand-designed agents. Considering the tremendous number of building blocks yet to be discovered in\\nagentic systems (Section 5), it would take a long time for our research community to discover them\\nall. Even if we successfully discover most of the useful building blocks, combining them into effective\\nagentic systems for massive real-world applications would still be challenging and time-consuming,\\ngiven the many different ways the building blocks can combine and interact with each other. In\\ncontrast, with ADAS, the building blocks and agents can be learned in an automated fashion. ADAS\\n2\\nAutomated Design of Agentic Systems\\nmay not only potentially save human effort in developing powerful agents but also could be a faster\\npath to more effective solutions than manual design.\\nAlthough a few existing works can be considered as ADAS methods, most of them focus only on\\ndesigning prompts (Fernando et al., 2024; Yang et al., 2024), greatly limiting their ability to invent\\nflexible design patterns in agents (Section 5). In this paper, we show that there is an unexplored\\nyet promising approach to ADAS where we can define the entire agentic system in code and new\\nagents can be automatically discovered by a ‚Äúmeta‚Äù agent programming even better ones in code.\\nGiven that most programming languages, such as Python, which we use in this paper, are Turing\\nComplete (Boyer & Moore, 1983; Ladha, 2024), searching within a code space theoretically enables a\\nADAS algorithm to discover anypossible agentic systems, including all components such as prompts,\\ntool use, control flows, and more. Furthermore, with recent FMs being increasingly proficient in\\ncoding, we can use FMs as a meta agent to create new agents in code for ADAS, enabling novel agents\\nto be programmed in an automated manner.\\nFollowing the aforementioned ideas, we present Meta Agent Search in this paper as one of the first\\nalgorithms in ADAS that enables complete design in code space (Figure 1). The core concept of Meta\\nAgent Search is to instruct a meta agent to iteratively create interestingly new agents, evaluate them,\\nadd them to an archive that stores discovered agents, and use this archive to help the meta agent in\\nsubsequent iterations create yet more interestingly new agents. Similar to existing open-endedness\\nalgorithms that leverage human notions of interestingness (Lu et al., 2024c; Zhang et al., 2024a),\\nwe encourage the meta agent to explore interesting (e.g., novel or worthwhile) agents. To validate\\nthe proposed approach, we evaluate the proposed Meta Agent Search on: (1) the challenging ARC\\nlogic puzzle task (Chollet, 2019) that aims to test the general intelligence of an AI system, (2) four\\npopular benchmarks on reading comprehension, math, science questions, and multi-task problem\\nsolving, and (3) the transferability of discovered agents to held-out domains and models (Section 4).\\nOur experiments show that the discovered agents substantially outperform state-of-the-art hand-\\ndesigned baselines. For instance, our agents improve F1 scores on reading comprehension tasks in\\nDROP (Dua et al., 2019) by 13.6/100 and accuracy rates on math tasks in MGSM (Shi et al., 2023) by\\n14.4%. Additionally, they improve accuracy over baselines by 25.9%and13.2%on GSM8K (Cobbe\\net al., 2021) and GSM-Hard (Gao et al., 2023) math tasks, respectively, after transferring across\\ndomains. The promising performance of our algorithm over hand-designed solutions illustrates\\nthe potential of ADAS in automating the design of agentic systems. Furthermore, the experiments\\ndemonstrate that the discovered agents not only perform well when transferring across similar\\ndomains but also exhibit strong performance when transferring across dissimilar domains, such as\\nfrom mathematics to reading comprehension. This highlights the robustness and transferability of the\\nagentic systems discovered by Meta Agent Search. In conclusion, our work opens up many exciting\\nresearch directions and encourages further studies (Section 6).\\n2. New Research Area: Automated Design of Agentic Systems (ADAS)\\nAt the time of writing, the community has not reached a consensus on the definitions or terminologies\\nof agents. Here, by agents we refer to agentic systems that involve Foundation Models (FMs) as\\nmodules in the control flow to solve tasks by planning, using tools, and carrying out multiple, iterative\\nsteps of processing (Chase, 2024; Ng, 2024).\\nIn this paper, we propose a new research area Automated Design of Agentic Systems (ADAS).\\nSimilar to research areas in AI-GAs (Clune, 2019) and AutoML (Hutter et al., 2019), such as Neural\\nArchitecture Search (Elsken et al., 2019), we formulate ADAS as an optimization process and identify\\nthree key components of ADAS algorithms (Figure 2).\\n3\\nAutomated Design of Agentic Systems\\nSearch Space\\nE.g. Agents defined by code\\nSearch Algorithm\\nE.g. LLM defines agents using code\\nEvaluation Function\\nE.g. Accuracy on the taskWhere is the capital of CanadaOttawa\\n‚úÖSampleNew AgentEvaluate the ObjectivesAgent‚Ä¶‚Ä¶1 + 1 = ?\\nFigure 2|The three key components of Automated Design of Agentic Systems (ADAS). The search\\nspace determines which agentic systems can be represented in ADAS. The search algorithm specifies\\nhow the ADAS method explores the search space. The evaluation function defines how to evaluate a\\ncandidate agent on target objectives such as performance.\\nFormulation\\nAutomated Design of Agentic Systems (ADAS) involves using a search algorithm to discover\\nagentic systems across a search space thatoptimize anevaluation function .\\n‚Ä¢Search Space : The search space defines which agentic systems can be represented and thus\\ndiscovered in ADAS. For example, works like PromptBreeder (Fernando et al., 2024) mutate only\\nthe text prompts of an agent, but their other components, such as control flow, remain the same.\\nThus, in these search spaces, agents that have a different control flow than the predefined one can\\nnot be represented. Existing works also explore search spaces such as graph structures (Zhuge\\net al., 2024) and feed-forward networks (Liu et al., 2023).\\n‚Ä¢Search Algorithm : The search algorithm defines how ADAS algorithms explore the search space.\\nSince the search space is often very large or even unbounded, the exploration-exploitation trade-\\noff (Sutton & Barto, 2018) should be considered. Ideally, the algorithm can both quickly discover\\nhigh-performance agentic systems and avoid remaining stuck in a local optimum. Existing ap-\\nproachesincludeusingReinforcementLearning(Zhugeetal.,2024)oranFMiterativelygenerating\\nnew solutions (Fernando et al., 2024) as search algorithms.\\n‚Ä¢Evaluation Function : Depending on the application of the ADAS algorithm, we may consider\\ndifferentobjectivestooptimize,suchasperformance,cost,latency,orsafetyofagents. Anevaluation\\nfunction defines how to evaluate a candidate agent on those objectives. For example, to assess\\nthe agent‚Äôs performance on unseen future data, a simple method is to calculate the accuracy rate\\non the validation data for a task, which is commonly adopted in existing works (Fernando et al.,\\n2024; Zhuge et al., 2024).\\nAlthoughmanysearchspacedesignsarepossibleandsomehavealreadybeenexplored(Section5),\\nthere is an unexplored yet promising approach where we can define the entire agentic system in\\ncode and new agents can be automatically discovered by a meta agent programming even better\\nones in code. Searching within a code space theoretically enables the ADAS algorithm to discover\\nanypossible building blocks (e.g., prompts, tool use, control flow) and agentic systems that combine\\nany of these building blocks in any way. This approach also offers better interpretability for agent\\ndesign patterns since the program code is often readable, making debugging easier and enhancing AI\\nsafety. Additionally, compared to search spaces using networks (Liu et al., 2023) or graphs (Zhuge\\net al., 2024), searching in a code space allows us to more easily build on existing human efforts. For\\nexample, it is possible to search within open-source agent frameworks like LangChain (LangChainAI,\\n2022) and build upon all existing building blocks (e.g., RAG, search engine tools). Finally, since FMs\\n4\\nAutomated Design of Agentic Systems\\nare proficient in coding, utilizing a code search space allows us to leverage existing expertise from\\nFMs during the search process. In contrast, search algorithms in custom search spaces, such as graphs,\\nmay be much less efficient due to the absence of these priors. Therefore, we argue that the approach\\nof using programming languages as the search space should be studied more in ADAS.\\n3. Our Algorithm: Meta Agent Search\\nIn this section, we present Meta Agent Search, a simple yet effective algorithm to demonstrate the\\napproach of defining and searching for agents in code. The core idea of Meta Agent Search is to adopt\\nFMs as meta agents to iteratively program interestingly new agents based on an ever-growing archive\\nof previous discoveries. Although any possible building blocks and agentic systems can theoretically\\nbe programmed by the meta agent from scratch, it is inefficient in practice to avoid providing the\\nmeta agent any basic functions such as FM query APIs or existing tools. Therefore, in this paper, we\\ndefine a simple framework (within 100 lines of code) for the meta agent, providing it with a basic\\nset of essential functions like querying FMs or formatting prompts. As a result, the meta agent only\\nneeds to program a ‚Äúforward‚Äù function to define a new agentic system, similar to the practice in\\nFunSearch (Romera-Paredes et al., 2024). This function takes in the information of the task and\\noutputs the agent‚Äôs response to the task. Details of the framework codes and examples of the agents\\ndefined with this framework can be found in Appendix B.\\nAs shown in Figure 1, the core idea of Meta Agent Search is to have a meta agent iteratively\\nprogram new agents in code. We show the main prompt for the meta agent to program new agents\\nbelow, where variables in the prompts are highlighted. Similar to existing open-endedness algorithms\\nthat leverage human notions of interestingness (Lu et al., 2024c; Zhang et al., 2024a), we encourage\\nthe meta agent to explore interestingly new (e.g., novel or worthwhile) agents based on an ever-\\ngrowing archive of previous discoveries. We also adopt self-reflection (Madaan et al., 2024; Shinn\\net al., 2023) iterations in our meta agent, where it performs two iterations of refinement on the\\nnovelty and correctness of the proposal and performs up to three refinements when errors occur\\nwhile running the code. Full details of the prompt are presented in Appendix A.\\nAfter a new agent is generated, we evaluate it using the validation data from the target domain.\\nHere, we calculate the performance (e.g., success rate or F1 score) and 95% bootstrap confidence\\ninterval as the metrics for the meta agent to maximize. The generated agent is then added to the\\narchive with the evaluation metrics, and the iteration continues with the updated archive until the\\nmaximum number of iterations is reached.\\nMain prompt for the meta agent.\\nYou are an expert machine learning researcher testing different agentic systems.\\n[BriefDescriptionoftheDomain]\\n[FrameworkCode]\\n[OutputInstructionsandExamples]\\n[DiscoveredAgentArchive] (initializedwithbaselines,updatedateveryiteration)\\n# Your task\\nYou are deeply familiar with prompting techniques and the agent works from the literature. Your goal is\\nto maximize the performance by proposing interestingly new agents ......\\nUse the knowledge from the archive and inspiration from academic literature to propose the next\\ninteresting agentic system design.\\n5\\nAutomated Design of Agentic Systems\\n4. Experiments\\nWe conduct extensive experiments on: (1) the challenging ARC logic puzzle task (Chollet, 2019)\\n(Section 4.1), (2) four popular benchmarks assessing the agent‚Äôs abilities on reading comprehension,\\nmath, science questions, and multi-task problem solving (Section 4.2), (3) the transferability of\\nthe discovered agents on ARC to three held-out models, and (4) the transferability of discovered\\nagents on Math to four held-out math tasks and three tasks that are beyond math (Section 4.3).\\nAcross all experiments, we find that the discovered agents substantially outperform baseline state-\\nof-the-art hand-designed agents. Notably, our discovered agents improve over baselines on reading\\ncomprehension tasks in DROP (Dua et al., 2019) by 13.6/100 (F1 score) and on math tasks in\\nMGSM (Shi et al., 2023) by 14.4%(accuracy rate). Additionally, our discovered agents improve over\\nthe baseline on ARC tasks by 14%(accuracy rate) after transferring from GPT-3.5 to GPT-4, and by\\n25.9%and13.2%(accuracy rate) after transferring from MGSM math tasks to held-out math tasks in\\nGSM8K (Cobbe et al., 2021) and GSM-Hard (Gao et al., 2023) respectively. All code, prompts, and\\nexperiment results are available at https://github.com/ShengranHu/ADAS .\\n0 5 10 15 20 25\\nIteration468101214Held-out T est Accuracy (%)\\nInitially tested generating high-level strategies\\nbefore implementing low-level details.An important strategy emerged: using multiple COT s\\nto generate possible answers, refining them, and\\nfinally ensembling the best answers.Introduced dynamic memory for doing more refinements.Scaled up the previous idea.Best agent: introduced multiple\\ncritics for enhanced refinement.Meta-Agent Search on ARC\\nChain-of-Thought\\nSelf-Refine\\nLLM DebateCOT-SC\\nQuality-Diversity\\nMeta-Agent Search\\n(a)\\nTask5 COTs\\n5 Answers\\nHuman -like \\nCritic\\nFeedbackEfficiency Expert\\nReadability Expert\\nSimplicity ExpertExperts\\nFeedback\\nRefinement\\n3 timesAll \\nAnswers\\nEvaluateTop-3 \\nAnswersEnsembleFinal \\nAnswer\\nStructured Feedback and Ensemble AgentThe Best Discovered Agent on ARC (b)\\nFigure 3|The results of Meta Agent Search on the ARC challenge. (a) Meta Agent Search progres-\\nsively discovers high-performance agents based on an ever-growing archive of previous discoveries.\\nWe report the median accuracy and the 95% bootstrap confidence interval on a held-out test set by\\nevaluating agents five times. (b) The visualization of the best agent discovered by Meta Agent Search\\non the ARC challenge. Detailed implementation of this agent is available in Appendix C.\\n4.1. Case Study: ARC Challenge\\nWefirstdemonstratehowMetaAgentSearchdiscoversnovelagenticsystemsandoutperformsexisting\\nstate-of-the-art hand-designed agents in the Abstraction and Reasoning Corpus (ARC) challenge (Chol-\\nlet, 2019). This challenge aims to evaluate the general intelligence of AI systems through their ability\\nto efficiently acquire new skills. Questions in ARC include (1) showing multiple examples of visual\\ninput-output grid patterns, (2) the AI system learning the transformation rule of grid patterns from\\nexamples, and (3) predicting the output grid pattern given a test input grid pattern. Since each\\nquestion in ARC has a unique transformation rule, it requires the AI system to learn efficiently with\\n6\\nAutomated Design of Agentic Systems\\nfew-shot examples, leveraging capabilities in number counting, geometry, and topology.\\nSetup. Following common practice (Greenblatt, 2024), we require the agent to write code for the\\ntransformation rule instead of answering directly. We provide tool functions in the framework that\\nevaluate the generated transformation code. Given the significant challenge that ARC poses to current\\nAI systems, we sample our data from questions with grid dimensions ‚â§5√ó5in the ‚ÄúPublic Training\\nSet (Easy)‚Äù. We sample a validation set and a test set with 20 and 60 questions, respectively, for\\nsearching and testing. We calculate the validation and test accuracy of an agent by assessing it over\\nthe validation and test sets five times to reduce the variance from the stochastic sampling of FMs. We\\nevaluate all discovered agents on the held-out test set and report the test accuracy in Figure 3. Meta\\nAgent Search runs for 25 iterations and the meta agent uses GPT-4 (OpenAI, 2024), while discovered\\nagents and baselines are evaluated using GPT-3.5 (OpenAI, 2022) to reduce compute cost. More\\nalgorithmic details and examples of ARC questions can be found in Appendix C.\\nBaselines. We compared against five state-of-the-art hand-designed agents: (1) Chain-of-Thought\\n(COT) (Wei et al., 2022), which instructs the agent to output the reasoning before answering to\\nimprove complex problem-solving through intermediate steps; (2) Self-Consistency with Chain-of-\\nThought (COT-SC) (Wang et al., 2023b), which ensembles multiple parallel answers from COT to\\nproduce a more accurate answer; (3) Self-Refine (Madaan et al., 2024; Shinn et al., 2023), which\\nallows iterative self-reflection to correct mistakes made in previous attempts; (4) LLM-Debate (Du\\net al., 2023), which enables different LLMs to debate with each other, leveraging diverse perspectives\\nto find better answers; (5) Quality-Diversity, a simplified version of Intelligent Go-Explore (Lu et al.,\\n2024c), which produces and ensembles diverse answers to better explore potential solutions. We also\\nuse all baselines as initial seeds in the archive for Meta Agent Search. More details about baselines\\ncan be found in Appendix E.\\nResults and Analysis. As shown in Figure 3a, Meta Agent Search effectively and progressively\\ndiscovers agents that perform better than state-of-the-art hand-designed baselines. Important break-\\nthroughs are highlighted in the text boxes. As is critical in prior works on open-endedness and AI-GAs\\n(Faldor et al., 2024; Lehman & Stanley, 2011; Wang et al., 2019, 2020; Zhang et al., 2024a), Meta\\nAgent Search innovates based on a growing archive of previous stepping stones. For example, an\\nimportant design pattern emerged in iteration 3 where it uses multiple COTs to generate possible\\nanswers, refines them, and finally ensembles the best answers. This became a crucial stepping\\nstone that subsequent designs tended to utilize. Additionally, the best-discovered agent is shown\\nin Figure 3b, where a complex feedback mechanism is adopted to refine answers more effectively.\\nCareful observation of the search progress reveals that this sophisticated feedback mechanism did\\nnot appear suddenly. Instead, the ideas of incorporating diverse feedback, evaluating for various\\nspecific traits (via experts) such as efficiency and simplicity, and simulating human-like feedback\\nemerged in iterations 5, 11, and 12, respectively. The final mechanism is an innovation based on\\nthese three stepping stones. This illustrates that even though these stepping stones did not achieve\\nhigh performance immediately upon emergence, later discoveries benefited from these innovations\\nby combining different stepping stones, resembling crossover in evolution via LLMs (Meyerson et al.,\\n2023). Overall, the results showcase the potential of ADAS and the effectiveness of Meta Agent Search\\nto progressively discover agents that outperform state-of-the-art hand-designed baselines and invent\\nnovel design patterns through the innovation and combination of various stepping stones.\\n4.2. Reasoning and Problem-Solving Domains\\nSetup. Next,weinvestigatethepotentialofouralgorithmtoimprovethecapabilitiesofagentsacross\\nmath, reading, and reasoning domains. We test Meta Agent Search on four popular benchmarks: (1)\\nDROP (Dua et al., 2019) for evaluating Reading Comprehension ; (2) MGSM (Shi et al., 2023) for\\n7\\nAutomated Design of Agentic Systems\\nAgent NameF1 Score Accuracy (%)\\nReading Comprehension Math Multi-task Science\\nState-of-the-art Hand-designed Agents\\nChain-of-Thought (Wei et al., 2022) 64.2¬±0.9 28 .0¬±3.1 65 .4¬±3.3 29 .2¬±3.1\\nCOT-SC (Wang et al., 2023b) 64.4¬±0.8 28 .2¬±3.165.9¬±3.230.5¬±3.2\\nSelf-Refine (Madaan et al., 2024) 59.2¬±0.9 27 .5¬±3.1 63 .5¬±3.431.6¬±3.2\\nLLM Debate (Du et al., 2023) 60.6¬±0.9 39.0¬±3.465.6¬±3.3 31 .4¬±3.2\\nStep-back Abstraction (Zheng et al., 2023) 60.4¬±1.0 31 .1¬±3.2 65 .1¬±3.3 26 .9¬±3.0\\nQuality-Diversity (Lu et al., 2024c) 61.8¬±0.9 23 .8¬±3.0 65 .1¬±3.3 30 .2¬±3.1\\nRole Assignment (Xu et al., 2023) 65.8¬±0.9 30.1¬±3.2 64 .5¬±3.3 31 .1¬±3.1\\nAutomated Design of Agentic Systems on Different Domains\\nBest Agents from Meta Agent Search 79.4¬±0.8 53 .4¬±3.5 69 .6¬±3.2 34 .6¬±3.2\\nTable 1|Performance comparison between Meta Agent Search and state-of-the-art hand-\\ndesigned agents across multiple domains. Meta Agent Search discovers superior agents compared\\nto the baselines in every domain. We report the test accuracy and the 95% bootstrap confidence\\ninterval on held-out test sets. The search is conducted independently for each domain.\\nevaluating Mathcapability under a multi-lingual setting; (3) MMLU (Hendrycks et al., 2021) for\\nevaluating Multi-task Problem Solving; and (4) GPQA (Rein et al., 2023) for evaluating the capability\\nof solving hard (graduate-level) questions in Science. The search is conducted independently within\\neach domain. Meta Agent Search runs for 30 iterations. The meta agent uses GPT-4 (OpenAI, 2024),\\nwhile the discovered agents and baselines are evaluated using GPT-3.5 (OpenAI, 2022). More details\\nabout datasets and experiment settings can be found in Appendix D.\\nBaselines. We adopt all baselines introduced in Section 4.1. Additionally, since the above domains\\nrequirestrongreasoningskills,weincludetwoadditionalbaselinesthatspecificallyfocusonenhancing\\nthereasoningcapabilitiesofagentsforamorethoroughcomparison: (1)Step-backAbstraction(Zheng\\net al., 2023), which instructs agents to first consider the principles involved in solving the task for\\nbetter reasoning; (2) Role Assignment, which assigns different roles to FMs similar to Xu et al. (2023)\\nto obtain better answers. More details about the baselines can be found in Appendix E.\\nResults and Analysis. The results across multiple domains demonstrate that Meta Agent Search\\ncan discover agents that outperform state-of-the-art hand-designed agents (Table 1). We want to\\nhighlight the substantial gap between the learned agents and hand-designed agents in the Reading\\nComprehension and Math domains, with improvements in F1 scores by 13.6/100 and accuracy rates\\nby14.4%, respectively. While Meta Agent Search also outperforms baselines in the Multi-task and\\nScience domains, the gap is smaller. We hypothesize that for challenging questions in the Science\\nand Multi-task domains, the knowledge in FMs is not sufficient to solve the questions, limiting the\\nimprovement through optimizing agentic systems, which is a problem that will diminish as FMs\\nimprove. In contrast, in the Reading Comprehension and Math domains, FMs possess adequate\\nknowledge to solve the questions, and errors could mainly be hallucinations or calculation mistakes,\\nwhich can be mitigated through well-designed agentic systems, like the ones discovered by Meta\\nAgent Search. Overall, the results across various domains showcase the effectiveness of Meta Agent\\nSearch in searching for agents tailored to specific domains. This could be increasingly useful for\\nsaving human efforts and developing better task-specific agents as we continue to create agents for a\\ndiverse set of applications (Wang et al., 2024).\\n8\\nAutomated Design of Agentic Systems\\n4.3. Generalization and transferability\\nAgent NameAccuracy on ARC (%)\\nGPT-3.5 Claude-Haiku GPT-4 Claude-Sonnet\\nManually Designed Agents\\nChain-of-Thought (Wei et al., 2022) 6.0¬±2.7 4.3¬±2.2 17 .7¬±4.4 25 .3¬±5.0\\nCOT-SC (Wang et al., 2023b) 8.0¬±3.2 5.3¬±2.5 19 .7¬±4.5 26 .3¬±4.9\\nLLM Debate (Du et al., 2023) 4.0¬±2.2 1.7¬±1.5 19 .0¬±4.5 24 .7¬±4.8\\nSelf-Refine (Madaan et al., 2024) 6.7¬±2.7 6.3¬±2.8 23 .0¬±5.2 39 .3¬±5.5\\nQuality-Diversity (Lu et al., 2024c) 7.0¬±2.9 3.3¬±2.2 23.0¬±4.7 31.7¬±5.3\\nTop Agents Searched with GPT-3.5 Transferred to Other FMs\\nStructured Feedback and Ensemble Agent 13.7¬±3.9 5.0¬±2.5 30 .0¬±5.2 38 .7¬±5.5\\nHierarchical Committee Reinforcement Agent 13.3¬±3.8 8.3¬±3.2 32 .3¬±8.9 39 .7¬±5.5\\nDynamic Memory and Refinement Agent‚Ä†12.7¬±3.9 9.7¬±3.3 37 .0¬±5.3 48 .3¬±5.7\\nTable 2|Performance on ARC when transferring top agents from GPT-3.5 to other FMs. Agents\\ndiscovered by Meta Agent Search consistently outperform the baselines across different models. We\\nreport the test accuracy and the 95% bootstrap confidence interval. The names of top agents are\\ngenerated by Meta Agent Search.‚Ä†We manually changed this name because the original generated\\nname was confusing.\\nIn the previous sections, we illustrated that Meta Agent Search can find effective agents for\\nindividual tasks. In this section, we further demonstrate the transferability and generalizability of the\\ndiscovered agents. To show that the invented building blocks and design patterns are generalizable,\\nwe conduct experiments on the transferability of the discovered agents.\\nTransferability Across Foundation Models. We first transfer discovered agents from GPT-3.5 (Ope-\\nnAI, 2022) to other FMs on ARC to test whether agents found when performing Meta Agent Search\\nwith one FM generalize to others. We test the top 3 agents with the best test accuracy evaluated with\\nGPT-3.5 on ARC and then transfer them to three popular models: Claude-Haiku (Anthropic, 2024a),\\nGPT-4 (OpenAI, 2024), and Claude-Sonnet (Anthropic, 2024b). We adopt the same baselines as\\nthose used in ARC (Section 4.1) and MGSM (Section 4.2). As shown in Table 2, we observe that the\\nsearched agents consistently outperform the hand-designed agents with a substantial gap. Notably,\\nwe found that Claude-Sonnet, the most powerful model from Anthropic, performs the best among all\\ntested models, enabling our best agent to achieve nearly 50% accuracy on ARC.\\nTransferability Across Domains. Next, we transfer the discovered agent from the MGSM (Math)\\ndomain to other math domains to test whether the invented agents can generalize across different\\ndomains. Similarly, we test the top 3 agents from MGSM and transfer them to (1) four popular math\\ndomains: GSM8K (Cobbe et al., 2021), GSM-Hard (Gao et al., 2023), SVAMP (Patel et al., 2021),\\nand ASDiv (Miao et al., 2020) and (2) three domains beyond math adopted in Section 4.2. As shown\\nin Table 3, we observe a similar superiority in the performance of Meta Agent Search compared to\\nbaselines. Notably, our agents improve accuracy by 25.9%and13.2%on GSM8K (Cobbe et al., 2021)\\nand GSM-Hard (Gao et al., 2023), respectively, compared to the baselines. More surprisingly, we\\nobserve that agents discovered in the math domain can be transferred to non-math domains (Table 4).\\nWhile the performance of agents originally searched in the math domain does not fully match that of\\nagents specifically designed for the target domains, they still outperform (in Reading Comprehension\\nand Multi-task) or match (in Science) the state-of-the-art hand-designed agent baselines. These\\nresults illustrate that Meta Agent Search can discover generalizable design patterns and agentic\\nsystems.\\n9\\nAutomated Design of Agentic Systems\\nAgent NameAccuracy (%)\\nMGSM GSM8K GSM-Hard SVAMP ASDiv\\nManually Designed Agents\\nChain-of-Thought (Wei et al., 2022) 28.0¬±3.134.9¬±3.2 15 .0¬±2.5 77 .8¬±2.8 88 .9¬±2.2\\nCOT-SC (Wang et al., 2023b) 28.2¬±3.137.8¬±3.4 15 .5¬±2.5 78 .2¬±2.8 89 .0¬±2.1\\nSelf-Refine (Madaan et al., 2024) 27.5¬±3.138.9¬±3.4 15 .1¬±2.478.5¬±2.8 89 .2¬±2.2\\nLLM Debate (Du et al., 2023) 39.0¬±3.443.6¬±3.417.4¬±2.6 76 .0¬±3.0 88 .9¬±2.2\\nStep-back Abstraction (Zheng et al., 2023) 31.1¬±3.231.5¬±3.3 12 .2¬±2.3 76 .1¬±3.0 87 .8¬±2.3\\nQuality-Diversity (Lu et al., 2024c) 23.8¬±3.028.0¬±3.1 14 .1¬±2.4 69 .8¬±3.2 80 .1¬±2.8\\nRole Assignment (Xu et al., 2023) 30.1¬±3.237.0¬±3.418.0¬±2.773.0¬±3.0 83 .1¬±2.6\\nTop Agents Searched on MGSM (Math) Transferred to Other Math Domains\\nDynamic Role-Playing Architecture 53.4¬±3.569.5¬±3.2 31 .2¬±3.281.5¬±2.691.8¬±1.8\\nStructured Multimodal Feedback Loop 50.2¬±3.564.5¬±3.4 30 .1¬±3.282.6¬±2.689.9¬±2.1\\nInteractive Multimodal Feedback Loop 47.4¬±3.564.9¬±3.3 27 .6¬±3.2 80 .6¬±2.8 89 .8¬±2.1\\nTable 3|Performance on different math domains when transferring top agents from MGSM to\\nother math domains. Agents discovered by Meta Agent Search consistently outperform the baselines\\nacross different math domains. We report the test accuracy and the 95% bootstrap confidence interval.\\nThe names of top agents are generated by Meta Agent Search.\\n5. Related Work\\nAgentic Systems. Researchers develop various building blocks and design patterns for different\\napplications. Important building blocks for agentic systems includes: prompting techniques (Chen\\net al., 2023a; Schulhoff et al., 2024), chain-of-thought-based planning and reasoning methods (Hu\\n& Clune, 2024; Wei et al., 2022; Yao et al., 2023), reflection (Madaan et al., 2024; Shinn et al.,\\n2023), developing new skills for embodied agents in code (Vemprala et al., 2023; Wang et al., 2023a),\\nexternal memory and RAG (Lewis et al., 2020; Zhang et al., 2024c), tool use (Nakano et al., 2021;\\nQu et al., 2024; Schick et al., 2023), assigning FM modules in the agentic system with different\\nroles and enabling them to collaborate (Hong et al., 2023; Qian et al., 2023, 2024; Wu et al., 2023;\\nXu et al., 2023), and enabling the agent to instruct itself for the next action (Richards, 2023), etc.\\nWhile the community has invested substantial effort in developing all the above important techniques,\\nthis is only a partial list of the discovered building blocks, and many more remain to be uncovered.\\nTherefore, in this paper, we propose a new research area, ADAS, which aims to invent novel building\\nblocks and design powerful agentic systems in an automated manner.\\nAI-Generating Algorithms and AutoML. Following the lessons learned from the history of machine\\nlearning, research in AI-Generating Algorithms (AI-GAs) (Clune, 2019) and AutoML (Hutter et al.,\\n2019) continually strives to learn more components in AI systems to replace handcrafted ones. There\\nare mainly three pillars in this field: (1) meta-learning architectures, (2) meta-learning the learning\\nalgorithms, and (3) generating effective learning environments and training data (Clune, 2019). For\\nexample, Neural Architecture Search (Elsken et al., 2019; Hu et al., 2021; Lu et al., 2019) aims to\\nautomate the design of neural network architectures like convolution, which falls under the first pillar.\\nThe second pillar includes works like MAML (Finn et al., 2017) and Meta-RL (Duan et al., 2017;\\nNorman & Clune, 2023; Wang et al., 2016; Zintgraf et al., 2021a,b), which allow ‚Äúlearning to learn‚Äù\\nfor better sample efficiency, generalizability, and continuous learning of multiple tasks. Additionally,\\nworks like POET (Dharna et al., 2020; Wang et al., 2019, 2020) and OMNI-EPIC (Faldor et al., 2024)\\nunder the third pillar aim to generate learning environments in an open-ended manner. We believe\\n10\\nAutomated Design of Agentic Systems\\nAgent NameAccuracy (%) F1 Score Accuracy (%)\\nMath Reading Comprehension Multi-task Science\\nManually Designed Agents\\nChain-of-Thought (Wei et al., 2022) 28.0¬±3.1 64.2¬±0.9 65 .4¬±3.3 29 .2¬±3.1\\nCOT-SC (Wang et al., 2023b) 28.2¬±3.1 64.4¬±0.8 65.9¬±3.230.5¬±3.2\\nSelf-Refine (Madaan et al., 2024) 27.5¬±3.1 59.2¬±0.9 63 .5¬±3.431.6¬±3.2\\nLLM Debate (Du et al., 2023) 39.0¬±3.4 60.6¬±0.9 65 .6¬±3.3 31 .4¬±3.2\\nStep-back Abstraction (Zheng et al., 2023) 31.1¬±3.2 60.4¬±1.0 65 .1¬±3.3 26 .9¬±3.0\\nQuality-Diversity (Lu et al., 2024c) 23.8¬±3.0 61.8¬±0.9 65 .1¬±3.1 30 .2¬±3.1\\nRole Assignment (Xu et al., 2023) 30.1¬±3.2 65.8¬±0.9 64.5¬±3.3 31 .1¬±3.1\\nTop Agents Searched on Math (MGSM) Transferred beyond Math Domains\\nDynamic Role-Playing Architecture 53.4¬±3.5 70.4¬±0.9 62 .4¬±3.4 28 .6¬±3.1\\nStructured Multimodal Feedback Loop 50.2¬±3.5 70.4¬±0.9 67.0¬±3.228.7¬±3.1\\nInteractive Multimodal Feedback Loop 47.4¬±3.5 71.9¬±0.8 64.8¬±3.329.9¬±3.2\\nTable 4|Performance across multiple domains when transferring top agents from the Math\\n(MGSM) domain to non-math domains. Agents discovered by Meta Agent Search in the math\\ndomain can outperform or match the performance of baselines after being transferred to domains\\nbeyond math. We report the test accuracy and the 95% bootstrap confidence interval.\\nthat the proposed Automated Design of Agentic Systems belongs to both the first and second pillars:\\nPillar one because ADAS meta-learns the architecture of agentic systems, but also Pillar two because\\nagents are proficient in in-context learning, thus ADAS can also be considered as learning to learn, as\\ndemonstrated in the ARC challenge (Section 4.1).\\nAdditionally, recent AI-GA and AutoML works have incorporated Foundation Models (FMs) to\\nwrite code. For example, in FunSearch (Romera-Paredes et al., 2024) and EoH (Liu et al., 2024),\\nFMs write code to discover better optimization algorithms. In DiscoPOP (Lu et al., 2024a), FMs\\nprogram the loss function for preference learning in FM alignment training (Rafailov et al., 2024).\\nAdditionally, Eureka (Ma et al., 2023) and language-to-reward (Yu et al., 2023) enable FMs to write\\nreward functions for reinforcement learning in robotics. Finally, OMNI-EPIC (Faldor et al., 2024)\\nenables FMs to create robotics learning environments by programming in code. Here, we adopt a\\nsimilar idea that enables FMs to program new agents in code.\\nExisting Attempts to ADAS. There are two categories of works that can be considered attempts at\\nADAS in the literature: those that learn better prompts only, and those that learn more components\\nin agents than just prompts. Most works fall into the first category: learning prompts only. Works like\\nOPRO (Yang et al., 2024), PromptBreeder (Fernando et al., 2024), and Self-Discover (Zhou et al.,\\n2024a) adopt FMs to automate prompt engineering for agents, primarily focusing on the phrasing of\\ninstructions in the prompt to enhance the reasoning capability of agents. Thus, the learned prompts\\nare domain-specific and difficult to generalize. Beyond instructions, works like EvoAgent (Yuan\\net al., 2024) and AgentVerse (Chen et al., 2023b) optimize role definition in the prompt, as assigning\\npersonas or roles to agents has been shown to be beneficial (Xu et al., 2023). Although tuning prompts\\neffectively improves performance, other important components in agentic systems remain fixed and\\nhand-designed, vastly limiting the space of agents that can be discovered.\\nThere are far fewer attempts in the second category, which involves learning more components\\nthan just prompts in agentic systems. Most represent agents as networks or graphs in the search\\nspace. In these formulations, the FM with a certain prompt is considered a transformation function\\nfor text on nodes, and the information flow of the text is considered as edges. DyLAN (Liu et al.,\\n11\\nAutomated Design of Agentic Systems\\n2023) starts with a fully connected feed-forward network and uses FMs to score the response quality\\nof nodes in each layer to prune the connections. DSPy (Khattab et al., 2024) first generates a set\\nof possible nodes and then optimizes across the Cartesian product of these nodes while optimizing\\nthe few-shot examples for nodes. GPT-Swarm (Zhuge et al., 2024) represents an agentic system in\\na graph with a predefined set of nodes and uses a Reinforcement Learning algorithm to optimize\\nthe possible connections between nodes while optimizing the prompt for each node in a separate\\nstage. Although these works allow the learning of control flow (optimizing edges in networks or\\ngraphs), many other components, such as whether and which tools to learn or even how many nodes\\nto have, are still not learned, greatly limiting the space of agents that can be discovered. Besides\\nlearning prompts and control flow, AgentOptimizer (Zhang et al., 2024b) learns the tools used in\\nagents, and Agent Symbolic Learning (Zhou et al., 2024b) learns prompts, tools, and control flow\\ntogether. While Agent Symbolic Learning shares similar motivations to learn more components in\\nagents, it manually designs the search space for each component separately, which may make it a\\nharder search space for search algorithms. In addition, it mainly improves agents based on an existing\\ncomplex agent, without showing the emergence of new design patterns or building blocks. In contrast,\\nour work represents all possible components in code, allowing the search to be easier by leveraging\\nhuman efforts in the existing codebase of agents and FMs‚Äô expertise in coding. We also demonstrate\\nhow novel and diverse building blocks and design patterns emerge from a set of basic agent designs,\\nillustrating the potential creativity that can emerge from ADAS.\\n6. Discussion and Conclusion\\nSafety Considerations. We strongly advise researchers to be aware of the safety concerns\\nwhen executing untrusted model-generated code in Meta Agent Search and other research\\ninvolvingcodegeneration. While it is highly unlikely that model-generated code will perform overtly\\nmaliciousactionsinourcurrentsettingsandwiththeFoundationModels(FMs)weuse, suchcodemay\\nstill act destructively due to limitations in model capability or alignment (Chen et al., 2021; Rokon\\net al., 2020). Ideally, sandbox environments can be used to safely run untrusted model-generated\\ncode (Chen et al., 2021; Yee et al., 2010).\\nMore broadly, research on more powerful AI systems raises the question of whether we should\\nbe conducting research to advance AI capabilities at all. That topic clearly includes the proposed\\nAutomatedDesignofAgenticSystems(ADAS)asanewareainAI-GAresearch, whichcouldpotentially\\ncontribute to an even faster way to create Artificial General Intelligence (AGI) than the current manual\\napproach (Clune, 2019). The question of whether and why we should pursue AGI and AI-GA has\\nbeen discussed in many papers (Bengio et al., 2024; Bostrom, 2002; Clune, 2019; Ecoffet et al., 2020;\\nYudkowsky et al., 2008), and is beyond the scope of this paper. Specifically as regards ADAS, we\\nbelieve it is net beneficial to publish this work. First, this work demonstrates that with the available\\nAPI access to powerful FMs, it is easy to program powerful ADAS algorithms, and do so without any\\nexpensive hardware like GPUs. We feel it is beneficial to let the community know such algorithms are\\npowerful and easy to create, so they can be informed and account for them. Moreover, by sharing this\\ninformation, we hope to motivate follow-up work into safe-ADAS, such as algorithms that conduct\\nADAS safely during both search itself (e.g. not risking running any harmful code) and that refuse\\nto create dishonest, unhelpful, and/or harmful agents. Such an open-source research approach to\\ncreate safe-ADAS could be a better way to create safer AI systems (Caldwell, 2011; Meta, 2024). One\\ndirection we find particularly promising is to simply ask the Meta Agent Search algorithm to be safe\\nduring training and only create helpful, harmless, honest agents, potentially incorporating ideas such\\nas Constitutional AI (Bai et al., 2022).\\n12\\nAutomated Design of Agentic Systems\\nFuture Work. Our work also opens up many future research directions. For example:\\n‚Ä¢Higher-order ADAS. Since the meta agent used in ADAS to program new agents in code is also\\nan agent, ADAS can become self-referential where the meta agent can be improved through ADAS\\nas well. It would be an exciting direction to have a higher order of meta-learning to allow the\\nlearning of the meta agent and even the meta-meta agent, etc. (Lu et al., 2023)\\n‚Ä¢Seeding ADAS with more existing building blocks. Although we can theoretically allow any\\ncomponents in agentic systems to be programmed from scratch in the code space, it is not efficient\\nin practice. Therefore, it would be interesting to explore ADAS by standing on the shoulders of\\nexisting human efforts, such as search engine tools, RAG (Lewis et al., 2020), or functions from\\nexisting agent frameworks like LangChain (LangChainAI, 2022). Additionally, it is interesting\\nto support multi-modal capabilities (e.g. vision) in FMs or allow different FMs to be available in\\nagentic systems. This will enable the meta agent to choose from different FMs flexibly according to\\nthe difficulty of the instruction and whether data privacy is a priority.\\n‚Ä¢Multi-objective ADAS. We only consider one objective (i.e., performance) to optimize in this\\npaper, but in practice, multiple objectives are often considered, such as cost, latency, and robustness\\nof agentic systems (Hu et al., 2021; Huang et al., 2023). Thus, integrating multi-objective search\\nalgorithms (Deb et al., 2002) in ADAS could be promising.\\n‚Ä¢Novelty search algorithms. In Meta Agent Search, the design of the search algorithm is rel-\\natively simple, focusing solely on exploring interesting new designs. A more careful design of\\nthe search algorithm can be a promising future direction. For example, one could incorporate\\nmore sophisticated ideas from Quality-Diversity (Cully & Demiris, 2017; Mouret & Clune, 2015),\\nAI-generating (Clune, 2019), and Open-ended Algorithms (Faldor et al., 2024; Stanley & Lehman,\\n2015; Stanley et al., 2019; Zhang et al., 2024a). One could also include more classic approaches\\nto balance exploration and exploitation (Liu et al., 2024; Sutton & Barto, 2018).\\n‚Ä¢More intelligent evaluation functions. In this work, we simply evaluate discovered agents on the\\nevaluation set and use the numerical performance results. However, this approach is both expensive\\nand misses a lot of information. A promising future direction is to enable the meta agent to analyze\\ndetailed running logs during the evaluation, which contain rich information on the failure and\\nsuccess modes for better debugging and improving agentic systems (Zhou et al., 2024b). Also,\\nmany tasks involve subjective answer evaluations (Chiang et al., 2024; Lu et al., 2024b) that do\\nnot have ground-truth answers. It is also important to design novel evaluation functions in ADAS\\nto address these tasks. Finally, in this work, we targeted only one domain during the search. It\\nwould be interesting to explore whether ADAS algorithms can design even better generalist agents\\nwhen specifically searching for agents capable of performing well across multiple domains.\\n‚Ä¢More complex domains. Additionally, we only evaluate Meta Agent Search on single-step QA\\ntasks in this paper. It would be interesting to extend the method to more complex domians, such\\nas real-world applications involving multi-step interaction with complex environments.\\n‚Ä¢Understanding the emergence of complexity from human organizations. Beyond potentially\\nsaving researchers‚Äô efforts and improving upon the manual design of agentic systems, the research\\nin ADAS is also scientifically intriguing as it sheds light on the origins of complexity emerging from\\nhuman organization and society. The agentic system is a machine learning system that operates\\nprimarily over natural language‚Äîa representation that is interpretable to humans and used by\\nhumans in constructing our organization and society. Thus, there is a close connection between\\nagentic systems and human organizations, as shown in works incorporating the organizational\\nstructure for human companies in agents (Hong et al., 2023) or simulating a human town with\\nagents (Park et al., 2023). Therefore, the study in ADAS may enable us to observe how to create\\na simple set of conditions and have an algorithm to bootstrap itself from simplicity to produce\\ncomplexity in a system akin to human society.\\n13\\nAutomated Design of Agentic Systems\\n‚Ä¢Towards a Better Understanding of FMs. Works from Neural Architecture Search (Huang et al.,\\n2023) show that by observing the emerged architecture, we could gain more insights into Neural\\nNetworks. In this paper, we also gained insights about FMs from the results. For example, the\\nbest agent with GPT-3.5 involves a complex feedback mechanism, but when we transfer to other\\nadvanced models, the agent with a simpler feedback mechanism but more refinement becomes a\\nbetter agent (Section 4.3). This shows that GPT-3.5 may have a worse capability in evaluating and\\nrefining the answers, so it needs a complex feedback mechanism for better refinement, while other\\nadvanced models benefit more from a simpler feedback mechanism.\\nConclusion. Inthispaper, weproposeanewresearchproblem, AutomatedDesignofAgenticSystems\\n(ADAS), which aims to automatically invent novel building blocks and design powerful agentic systems .\\nWe demonstrated that a promising approach to ADAS is to define agents in code, allowing new agents\\nto be automatically discovered by a ‚Äúmeta‚Äù agent programming them in code. Following this idea,\\nwe propose Meta Agent Search, where the meta agent iteratively builds on previous discoveries\\nto program interesting new agents. The experiments show that Meta Agent Search consistently\\noutperforms state-of-the-art hand-designed agents across an extensive number of domains, and the\\ndiscovered agents transfer well across models and domains. Overall, our work illustrates the potential\\nof an exciting new research direction toward full automation in developing powerful agentic systems\\nfrom the bottom up.\\nAcknowledgments\\nThis work was supported by the Vector Institute, the Canada CIFAR AI Chairs program, grants from\\nSchmidt Futures and Open Philanthropy, an NSERC Discovery Grant, and a generous donation from\\nRafael Cosman. We thank Jenny Zhang, Rach Pradhan, Ruiyu Gou, Nicholas Ioannidis, and Eunjeong\\nHwang for insightful discussions and feedback.\\n14\\nAutomated Design of Agentic Systems\\nReferences\\nAnthropic. Introducing the next generation of claude. https://www.anthropic.com/news/\\nclaude-3-family , March 2024a. Blog post.\\nAnthropic. Introducing claude 3.5 sonnet. https://www.anthropic.com/news/\\nclaude-3-5-sonnet , June 2024b. Blog post.\\nYuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna\\nChen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, et al. Constitutional ai: Harmlessness\\nfrom ai feedback. arXiv preprint arXiv:2212.08073 , 2022.\\nYoshua Bengio, Geoffrey Hinton, Andrew Yao, Dawn Song, Pieter Abbeel, Trevor Darrell, Yuval Noah\\nHarari, Ya-Qin Zhang, Lan Xue, Shai Shalev-Shwartz, et al. Managing extreme ai risks amid rapid\\nprogress. Science, 384(6698):842‚Äì845, 2024.\\nN Bostrom. Existential Risks: analyzing human extinction scenarios and related hazards. Journal of\\nEvolution and Technology , 9, 2002.\\nRobert S Boyer and J Strother Moore. A mechanical proof of the Turing completeness of pure LISP .\\nCiteseer, 1983.\\nTracey Caldwell. Ethical hackers: putting on the white hat. Network Security , 2011(7):10‚Äì13, 2011.\\nHarrison Chase. What is an agent? https://blog.langchain.dev/what-is-an-agent/ , June\\n2024. Blog post.\\nBanghao Chen, Zhaofeng Zhang, Nicolas Langren√©, and Shengxin Zhu. Unleashing the poten-\\ntial of prompt engineering in large language models: a comprehensive review. arXiv preprint\\narXiv:2310.14735 , 2023a.\\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared\\nKaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large\\nlanguage models trained on code. arXiv preprint arXiv:2107.03374 , 2021.\\nWeize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi Lu,\\nYi-Hsin Hung, Chen Qian, et al. Agentverse: Facilitating multi-agent collaboration and exploring\\nemergent behaviors. In The Twelfth International Conference on Learning Representations , 2023b.\\nWei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li, Dacheng Li,\\nHao Zhang, Banghua Zhu, Michael Jordan, Joseph E. Gonzalez, and Ion Stoica. Chatbot arena: An\\nopen platform for evaluating llms by human preference, 2024.\\nFran√ßois Chollet. On the measure of intelligence. arXiv preprint arXiv:1911.01547 , 2019.\\nJeff Clune. Ai-gas: Ai-generating algorithms, an alternate paradigm for producing general artificial\\nintelligence. arXiv preprint arXiv:1905.10985 , 2019.\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias\\nPlappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word\\nproblems. arXiv preprint arXiv:2110.14168 , 2021.\\nAntoineCullyandYiannisDemiris. Qualityanddiversityoptimization: Aunifyingmodularframework.\\nIEEE Transactions on Evolutionary Computation , 22(2):245‚Äì259, 2017.\\n15\\nAutomated Design of Agentic Systems\\nN. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In 2005 IEEE Computer\\nSociety Conference on Computer Vision and Pattern Recognition (CVPR‚Äô05) , volume 1, pp. 886‚Äì893\\nvol. 1, 2005. doi: 10.1109/CVPR.2005.177.\\nKalyanmoyDeb, AmritPratap, SameerAgarwal, andTAMTMeyarivan. Afastandelitistmultiobjective\\ngenetic algorithm: Nsga-ii. IEEE transactions on evolutionary computation , 6(2):182‚Äì197, 2002.\\nAaron Dharna, Julian Togelius, and Lisa B Soros. Co-generation of game levels and game-playing\\nagents. In Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Enter-\\ntainment , volume 16, pp. 203‚Äì209, 2020.\\nYilun Du, Shuang Li, Antonio Torralba, Joshua BTenenbaum, and Igor Mordatch. Improving factuality\\nand reasoning in language models through multiagent debate. arXiv preprint arXiv:2305.14325 ,\\n2023.\\nDheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner.\\nDROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs. In Jill\\nBurstein, Christy Doran, and Thamar Solorio (eds.), Proceedings of the 2019 Conference of the North\\nAmerican Chapter of the Association for Computational Linguistics: Human Language Technologies,\\nVolume 1 (Long and Short Papers) , pp. 2368‚Äì2378, Minneapolis, Minnesota, June 2019. Association\\nfor Computational Linguistics. doi: 10.18653/v1/N19-1246.\\nYan Duan, John Schulman, Xi Chen, Peter L. Bartlett, Ilya Sutskever, and Pieter Abbeel. RL^2: Fast\\nreinforcement learning via slow reinforcement learning. In International Conference on Learning\\nRepresentations , 2017.\\nAdrien Ecoffet, Jeff Clune, and Joel Lehman. Open questions in creating safe open-ended AI: Tensions\\nbetween control and creativity. In Conference on Artificial Life , pp. 27‚Äì35. MIT Press, 2020.\\nThomas Elsken, Jan Hendrik Metzen, and Frank Hutter. Neural architecture search: A survey. Journal\\nof Machine Learning Research , 20(55):1‚Äì21, 2019.\\nMaxence Faldor, Jenny Zhang, Antoine Cully, and Jeff Clune. Omni-epic: Open-endedness via\\nmodels of human notions of interestingness with environments programmed in code. arXiv preprint\\narXiv:2405.15568 , 2024.\\nChrisantha Fernando, Dylan Sunil Banarse, Henryk Michalewski, Simon Osindero, and Tim Rock-\\nt√§schel. Promptbreeder: Self-referential self-improvement via prompt evolution, 2024.\\nChelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of\\ndeep networks. In International conference on machine learning , pp. 1126‚Äì1135. PMLR, 2017.\\nLuyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and\\nGraham Neubig. Pal: Program-aided language models. In International Conference on Machine\\nLearning , pp. 10764‚Äì10799. PMLR, 2023.\\nRyan Greenblatt. Getting 50% sota on arc-agi with gpt-4. https://redwoodresearch.substack.\\ncom/p/getting-50-sota-on-arc-agi-with-gpt , July 2024. Technical Report.\\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob\\nSteinhardt. Measuring massive multitask language understanding. In International Conference on\\nLearning Representations , 2021.\\n16\\nAutomated Design of Agentic Systems\\nSirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang,\\nSteven Ka Shing Yau, Zijuan Lin, Liyang Zhou, et al. Metagpt: Meta programming for multi-agent\\ncollaborative framework. arXiv preprint arXiv:2308.00352 , 2023.\\nShengran Hu and Jeff Clune. Thought Cloning: Learning to think while acting by imitating human\\nthinking. Advances in Neural Information Processing Systems , 36, 2024.\\nShengran Hu, Ran Cheng, Cheng He, Zhichao Lu, Jing Wang, and Miao Zhang. Accelerating multi-\\nobjective neural architecture search by random-weight evaluation. Complex & Intelligent Systems ,\\npp. 1‚Äì10, 2021.\\nShihua Huang, Zhichao Lu, Kalyanmoy Deb, and Vishnu Naresh Boddeti. Revisiting residual networks\\nfor adversarial robustness. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition , pp. 8202‚Äì8211, 2023.\\nFrank Hutter, Lars Kotthoff, and Joaquin Vanschoren. Automated machine learning: methods, systems,\\nchallenges . Springer Nature, 2019.\\nOmar Khattab, Arnav Singhvi, Paridhi Maheshwari, Zhiyuan Zhang, Keshav Santhanam, Saiful\\nHaq, Ashutosh Sharma, Thomas T Joshi, Hanna Moazam, Heather Miller, et al. Dspy: Compiling\\ndeclarative language model calls into state-of-the-art pipelines. In The Twelfth International\\nConference on Learning Representations , 2024.\\nAlexKrizhevsky,IlyaSutskever,andGeoffreyEHinton. Imagenetclassificationwithdeepconvolutional\\nneural networks. Advances in neural information processing systems , 25, 2012.\\nAbrahim Ladha. Lecture 11: Turing-completeness. https://faculty.cc.gatech.edu/~ladha/\\nS24/4510/L11.pdf , 2024. CS 4510 Automata and Complexity, February 21st, 2024, Scribed by\\nRishabh Singhal.\\nLangChainAI. Langchain: Build context-aware reasoning applications. https://github.com/\\nlangchain-ai/langchain , 2022.\\nJoel Lehman and Kenneth O Stanley. Abandoning objectives: Evolution through the search for novelty\\nalone.Evolutionary computation , 19(2):189‚Äì223, 2011.\\nPatrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal,\\nHeinrich K√ºttler, Mike Lewis, Wen-tau Yih, Tim Rockt√§schel, et al. Retrieval-augmented generation\\nforknowledge-intensivenlptasks. AdvancesinNeuralInformationProcessingSystems ,33:9459‚Äì9474,\\n2020.\\nFei Liu, Tong Xialiang, Mingxuan Yuan, Xi Lin, Fu Luo, Zhenkun Wang, Zhichao Lu, and Qingfu\\nZhang. Evolution of heuristics: Towards efficient automatic algorithm design using large language\\nmodel. In Forty-first International Conference on Machine Learning , 2024.\\nZijun Liu, Yanzhe Zhang, Peng Li, Yang Liu, and Diyi Yang. Dynamic llm-agent network: An llm-agent\\ncollaboration framework with agent team optimization. arXiv preprint arXiv:2310.02170 , 2023.\\nChris Lu, Sebastian Towers, and Jakob Foerster. Arbitrary order meta-learning with simple population-\\nbased evolution. In ALIFE 2023: Ghost in the Machine: Proceedings of the 2023 Artificial Life\\nConference . MIT Press, 2023.\\nChris Lu, Samuel Holt, Claudio Fanconi, Alex J Chan, Jakob Foerster, Mihaela van der Schaar, and\\nRobert Tjarko Lange. Discovering preference optimization algorithms with and for large language\\nmodels. arXiv preprint arXiv:2406.08414 , 2024a.\\n17\\nAutomated Design of Agentic Systems\\nChris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, and David Ha. The AI Scientist:\\nTowards fully automated open-ended scientific discovery. arXiv preprint arXiv:2408.06292 , 2024b.\\nCong Lu, Shengran Hu, and Jeff Clune. Intelligent go-explore: Standing on the shoulders of giant\\nfoundation models. arXiv preprint arXiv:2405.15143 , 2024c.\\nZhichao Lu, Ian Whalen, Vishnu Boddeti, Yashesh Dhebar, Kalyanmoy Deb, Erik Goodman, and\\nWolfgang Banzhaf. Nsga-net: neural architecture search using multi-objective genetic algorithm.\\nInProceedings of the genetic and evolutionary computation conference , pp. 419‚Äì427, 2019.\\nYecheng Jason Ma, William Liang, Guanzhi Wang, De-An Huang, Osbert Bastani, Dinesh Jayaraman,\\nYuke Zhu, Linxi Fan, and Anima Anandkumar. Eureka: Human-level reward design via coding\\nlarge language models. In The Twelfth International Conference on Learning Representations , 2023.\\nAman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri\\nAlon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al. Self-refine: Iterative refinement with\\nself-feedback. Advances in Neural Information Processing Systems , 36, 2024.\\nMeta. Open source ai is the path forward. https://about.fb.com/news/2024/07/\\nopen-source-ai-is-the-path-forward/ , July 2024. News article.\\nElliot Meyerson, Mark J Nelson, Herbie Bradley, Adam Gaier, Arash Moradi, Amy K Hoover, and\\nJoel Lehman. Language model crossover: Variation through few-shot prompting. arXiv preprint\\narXiv:2302.12170 , 2023.\\nShen-yun Miao, Chao-Chun Liang, and Keh-Yih Su. A diverse corpus for evaluating and developing\\nenglish math word problem solvers. In Proceedings of the 58th Annual Meeting of the Association for\\nComputational Linguistics , pp. 975‚Äì984, 2020.\\nJean-Baptiste Mouret and Jeff Clune. Illuminating search spaces by mapping elites. arXiv preprint\\narXiv:1504.04909 , 2015.\\nReiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher\\nHesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. Webgpt: Browser-assisted question-\\nanswering with human feedback. arXiv preprint arXiv:2112.09332 , 2021.\\nAndrew Ng. Issue 253. https://www.deeplearning.ai/the-batch/issue-253/ , June 2024.\\nNewsletter issue.\\nBen Norman and Jeff Clune. First-explore, then exploit: Meta-learning intelligent exploration. arXiv\\npreprint arXiv:2307.02276 , 2023.\\nOpenAI. Introducing chatgpt. https://openai.com/index/chatgpt/ , November 2022. Blog\\npost.\\nOpenAI. Simple evals, 2023. URL https://github.com/openai/simple-evals . Accessed:\\n2024-08-10.\\nOpenAI. Gpt-4 technical report, 2024.\\nJoon Sung Park, Joseph O‚ÄôBrien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael S\\nBernstein. Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th\\nannual acm symposium on user interface software and technology , pp. 1‚Äì22, 2023.\\n18\\nAutomated Design of Agentic Systems\\nArkil Patel, Satwik Bhattamishra, and Navin Goyal. Are NLP models really able to solve simple\\nmath word problems? In Proceedings of the 2021 Conference of the North American Chapter of the\\nAssociation for Computational Linguistics: Human Language Technologies , pp. 2080‚Äì2094, Online,\\nJune 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.168.\\nChen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and Maosong\\nSun. Communicative agents for software development. arXiv preprint arXiv:2307.07924 , 2023.\\nChen Qian, Zihao Xie, Yifei Wang, Wei Liu, Yufan Dang, Zhuoyun Du, Weize Chen, Cheng Yang,\\nZhiyuan Liu, and Maosong Sun. Scaling large-language-model-based multi-agent collaboration.\\narXiv preprint arXiv:2406.07155 , 2024.\\nChangle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, and Ji-Rong\\nWen. Tool learning with large language models: A survey. arXiv preprint arXiv:2405.17935 , 2024.\\nRafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D Manning, Stefano Ermon, and Chelsea\\nFinn. Direct preference optimization: Your language model is secretly a reward model. Advances in\\nNeural Information Processing Systems , 36, 2024.\\nDavid Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani,\\nJulian Michael, and Samuel R. Bowman. Gpqa: A graduate-level google-proof q&a benchmark,\\n2023.\\nToran Bruce Richards. Autogpt. https://github.com/Significant-Gravitas/AutoGPT ,\\n2023. GitHub repository.\\nTim Rockt√§schel. Artificial Intelligence: 10 Things You Should Know . Seven Dials, September 2024.\\nISBN 978-1399626521.\\nMd Omar Faruk Rokon, Risul Islam, Ahmad Darki, Evangelos E Papalexakis, and Michalis Faloutsos.\\n{SourceFinder}: Finding malware {Source-Code}from publicly available repositories in {GitHub}.\\nIn23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020) , pp.\\n149‚Äì163, 2020.\\nBernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, M Pawan\\nKumar, Emilien Dupont, Francisco JR Ruiz, Jordan S Ellenberg, Pengming Wang, Omar Fawzi, et al.\\nMathematical discoveries from program search with large language models. Nature, 625(7995):\\n468‚Äì475, 2024.\\nTimo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke\\nZettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach\\nthemselves to use tools. In Thirty-seventh Conference on Neural Information Processing Systems ,\\n2023. URL https://openreview.net/forum?id=Yacmpz84TH .\\nSander Schulhoff, Michael Ilie, Nishant Balepur, Konstantine Kahadze, Amanda Liu, Chenglei Si,\\nYinheng Li, Aayush Gupta, HyoJung Han, Sevien Schulhoff, et al. The prompt report: A systematic\\nsurvey of prompting techniques. arXiv preprint arXiv:2406.06608 , 2024.\\nXuan Shen, Yaohua Wang, Ming Lin, Yilun Huang, Hao Tang, Xiuyu Sun, and Yanzhi Wang. Deepmad:\\nMathematical architecture design for deep convolutional neural network. In Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 6163‚Äì6173, 2023.\\nFreda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung Won\\nChung, Yi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das, and Jason Wei. Language models\\n19\\nAutomated Design of Agentic Systems\\nare multilingual chain-of-thought reasoners. In The Eleventh International Conference on Learning\\nRepresentations , 2023.\\nNoah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. Reflexion:\\nLanguage agents with verbal reinforcement learning. Advances in Neural Information Processing\\nSystems, 36, 2023.\\nKenneth O Stanley and Joel Lehman. Why greatness cannot be planned: The myth of the objective .\\nSpringer, 2015.\\nKenneth O Stanley, Jeff Clune, Joel Lehman, and Risto Miikkulainen. Designing neural networks\\nthrough neuroevolution. Nature Machine Intelligence , 1(1):24‚Äì35, 2019.\\nRichard S Sutton and Andrew G Barto. Reinforcement learning: An introduction . MIT press, 2018.\\nSai Vemprala, Rogerio Bonatti, Arthur Bucker, and Ashish Kapoor. Chatgpt for robotics:\\nDesign principles and model abilities. Technical Report MSR-TR-2023-8, Microsoft,\\nFebruary 2023. URL https://www.microsoft.com/en-us/research/publication/\\nchatgpt-for-robotics-design-principles-and-model-abilities/ .\\nGuanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and\\nAnima Anandkumar. Voyager: An open-ended embodied agent with large language models. arXiv\\npreprint arXiv: Arxiv-2305.16291 , 2023a.\\nJane X Wang, Zeb Kurth-Nelson, Dhruva Tirumala, Hubert Soyer, Joel Z Leibo, Remi Munos, Charles\\nBlundell, Dharshan Kumaran, and Matt Botvinick. Learning to reinforcement learn. arXiv preprint\\narXiv:1611.05763 , 2016.\\nLei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai\\nTang, Xu Chen, Yankai Lin, et al. A survey on large language model based autonomous agents.\\nFrontiers of Computer Science , 18(6):186345, 2024.\\nRui Wang, Joel Lehman, Jeff Clune, and Kenneth O. Stanley. Poet: open-ended coevolution of\\nenvironments and their optimized solutions. In Proceedings of the Genetic and Evolutionary Compu-\\ntation Conference , GECCO ‚Äô19, pp. 142‚Äì151, New York, NY, USA, 2019. Association for Computing\\nMachinery. ISBN 9781450361118. doi: 10.1145/3321707.3321799.\\nRui Wang, Joel Lehman, Aditya Rawal, Jiale Zhi, Yulun Li, Jeffrey Clune, and Kenneth Stanley.\\nEnhanced poet: Open-ended reinforcement learning through unbounded invention of learning\\nchallenges and their solutions. In International conference on machine learning , pp. 9940‚Äì9951.\\nPMLR, 2020.\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang, Aakanksha\\nChowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language\\nmodels. In The Eleventh International Conference on Learning Representations , 2023b.\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,\\net al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural\\ninformation processing systems , 35:24824‚Äì24837, 2022.\\nQingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang,\\nXiaoyun Zhang, and Chi Wang. Autogen: Enabling next-gen llm applications via multi-agent\\nconversation framework. arXiv preprint arXiv:2308.08155 , 2023.\\n20\\nAutomated Design of Agentic Systems\\nBenfeng Xu, An Yang, Junyang Lin, Quan Wang, Chang Zhou, Yongdong Zhang, and Zhendong Mao.\\nExpertprompting: Instructing large language models to be distinguished experts. arXiv preprint\\narXiv:2305.14688 , 2023.\\nChengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V Le, Denny Zhou, and Xinyun Chen.\\nLarge language models as optimizers. In The Twelfth International Conference on Learning Represen-\\ntations, 2024. URL https://openreview.net/forum?id=Bb4VGOWELI .\\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R Narasimhan, and Yuan\\nCao. React: Synergizing reasoning and acting in language models. In The Eleventh International\\nConference on Learning Representations , 2023. URL https://openreview.net/forum?id=WE_\\nvluYUL-X .\\nBennet Yee, David Sehr, Gregory Dardyk, J Bradley Chen, Robert Muth, Tavis Ormandy, Shiki Okasaka,\\nNeha Narula, and Nicholas Fullagar. Native client: A sandbox for portable, untrusted x86 native\\ncode.Communications of the ACM , 53(1):91‚Äì99, 2010.\\nWenhao Yu, Nimrod Gileadi, Chuyuan Fu, Sean Kirmani, Kuang-Huei Lee, Montserrat Gonzalez\\nArenas, Hao-Tien Lewis Chiang, Tom Erez, Leonard Hasenclever, Jan Humplik, et al. Language to\\nrewards for robotic skill synthesis. In Conference on Robot Learning , pp. 374‚Äì404. PMLR, 2023.\\nSiyu Yuan, Kaitao Song, Jiangjie Chen, Xu Tan, Dongsheng Li, and Deqing Yang. Evoagent: Towards\\nautomatic multi-agent generation via evolutionary algorithms. arXiv preprint arXiv:2406.14228 ,\\n2024.\\nEliezer Yudkowsky et al. Artificial Intelligence as a positive and negative factor in global risk. Global\\ncatastrophic risks , 1(303):184, 2008.\\nMatei Zaharia, Omar Khattab, Lingjiao Chen, Jared Quincy Davis, Heather Miller, Chris Potts,\\nJames Zou, Michael Carbin, Jonathan Frankle, Naveen Rao, and Ali Ghodsi. The shift\\nfrom models to compound ai systems. https://bair.berkeley.edu/blog/2024/02/18/\\ncompound-ai-systems/ , 2024.\\nJennyZhang, JoelLehman, KennethStanley, andJeffClune. OMNI:Open-endednessviamodelsofhu-\\nman notions of interestingness. In The Twelfth International Conference on Learning Representations ,\\n2024a. URL https://openreview.net/forum?id=AgM3MzT99c .\\nShaokun Zhang, Jieyu Zhang, Jiale Liu, Linxin Song, Chi Wang, Ranjay Krishna, and Qingyun\\nWu. Offline training of language model agents with functions as learnable weights. In Forty-first\\nInternational Conference on Machine Learning , 2024b.\\nZeyu Zhang, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, Quanyu Dai, Jieming Zhu, Zhenhua Dong, and\\nJi-Rong Wen. A survey on the memory mechanism of large language model based agents. arXiv\\npreprint arXiv:2404.13501 , 2024c.\\nHuaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen, Heng-Tze Cheng, Ed H Chi, Quoc V Le, and\\nDenny Zhou. Take a step back: Evoking reasoning via abstraction in large language models. arXiv\\npreprint arXiv:2310.06117 , 2023.\\nPei Zhou, Jay Pujara, Xiang Ren, Xinyun Chen, Heng-Tze Cheng, Quoc V Le, Ed H Chi, Denny Zhou,\\nSwaroop Mishra, and Huaixiu Steven Zheng. Self-discover: Large language models self-compose\\nreasoning structures. arXiv preprint arXiv:2402.03620 , 2024a.\\n21\\nAutomated Design of Agentic Systems\\nWangchunshu Zhou, Yixin Ou, Shengwei Ding, Long Li, Jialong Wu, Tiannan Wang, Jiamin Chen,\\nShuai Wang, Xiaohua Xu, Ningyu Zhang, et al. Symbolic learning enables self-evolving agents.\\narXiv preprint arXiv:2406.18532 , 2024b.\\nMingchen Zhuge, Wenyi Wang, Louis Kirsch, Francesco Faccio, Dmitrii Khizbullin, and J√ºrgen\\nSchmidhuber. Gptswarm: Language agents as optimizable graphs. In Forty-first International\\nConference on Machine Learning , 2024.\\nLuisaZintgraf,SebastianSchulze,CongLu,LeoFeng,MaximilianIgl,KyriacosShiarlis,YarinGal,Katja\\nHofmann, and Shimon Whiteson. Varibad: Variational bayes-adaptive deep rl via meta-learning.\\nJournal of Machine Learning Research , 22(289):1‚Äì39, 2021a.\\nLuisa M Zintgraf, Leo Feng, Cong Lu, Maximilian Igl, Kristian Hartikainen, Katja Hofmann, and\\nShimon Whiteson. Exploration in approximate hyper-state space for meta reinforcement learning.\\nInInternational Conference on Machine Learning , pp. 12991‚Äì13001. PMLR, 2021b.\\n22\\nAutomated Design of Agentic Systems\\nSupplementary Material\\nTable of Contents\\nA Prompts 24\\nB Framework Code 26\\nC Experiment Details for ARC Challenge 30\\nD Experiment Details for Reasoning and Problem-Solving Domains 33\\nE Baselines 35\\nF Example Agents 36\\nG Cost of Experiments 39\\n23\\nAutomated Design of Agentic Systems\\nA. Prompts\\nWe use the following prompts for the meta agent in Meta Agent Search. Variables in the prompts\\nthat vary depending on domains and iterations are highlighted. All detailed prompts are available at\\nhttps://github.com/ShengranHu/ADAS .\\nWe use the following system prompt for every query in the meta agent.\\nSystem prompt for the meta agent.\\nYou are a helpful assistant. Make sure to return in a WELL-FORMED JSON object.\\nWe use the following prompt for the meta agent to design the new agent based on the archive of\\npreviously discovered agents.\\nMain prompt for the meta agent.\\nYou are an expert machine learning researcher testing various agentic systems. Your objective is to design\\nbuilding blocks such as prompts and control flows within these systems to solve complex tasks. Your aim\\nis to design an optimal agent performing well on [BriefDescriptionoftheDomain].\\n[FrameworkCode]\\n[OutputInstructionsandExamples]\\n[DiscoveredAgentArchive] (initializedwithbaselines,updatedateveryiteration)\\n# Your task\\nYou are deeply familiar with prompting techniques and the agent works from the literature. Your goal is\\nto maximize the specified performance metrics by proposing interestingly new agents.\\nObserve the discovered agents carefully and think about what insights, lessons, or stepping stones can be\\nlearned from them.\\nBe creative when thinking about the next interesting agent to try. You are encouraged to draw inspiration\\nfrom related agent papers or academic papers from other research areas.\\nUse the knowledge from the archive and inspiration from academic literature to propose the next\\ninteresting agentic system design.\\nTHINK OUTSIDE THE BOX.\\nThe domain descriptions are available in Appendices C and D and the framework code is available\\nin Appendix B. We use the following prompt to instruct and format the output of the meta agent.\\nHere, we collect and present some common mistakes that the meta agent may make in the prompt.\\nWe found it effective in improving the quality of the generated code.\\nOutput Instruction and Example.\\n# Output Instruction and Example:\\nThe first key should be (‚Äúthought‚Äù), and it should capture your thought process for designing the\\nnext function. In the ‚Äúthought‚Äù section, first reason about what the next interesting agent to try\\nshould be, then describe your reasoning and the overall concept behind the agent design, and\\nfinally detail the implementation steps. The second key (‚Äúname‚Äù) corresponds to the name of\\nyour next agent architecture. Finally, the last key (‚Äúcode‚Äù) corresponds to the exact ‚Äúforward()‚Äù\\nfunction in Python code that you would like to try. You must write COMPLETE CODE in ‚Äúcode‚Äù:\\nYourcodewillbepartoftheentireproject, sopleaseimplementcomplete, reliable, reusablecodesnippets.\\n24\\nAutomated Design of Agentic Systems\\nHere is an example of the output format for the next agent:\\n{‚Äúthought‚Äù: ‚Äú**Insights:** Your insights on what should be the next interesting agent. **Overall Idea:**\\nyour reasoning and the overall concept behind the agent design. **Implementation:** describe the\\nimplementation step by step.‚Äù,\\n‚Äúname‚Äù: ‚ÄúName of your proposed agent‚Äù,\\n‚Äúcode‚Äù: ‚Äúdef forward(self, taskInfo): # Your code here‚Äù}\\n## WRONG Implementation examples:\\n[Examplesofpotentialmistakesthemetaagentmaymakeinimplementation]\\nAfter the first response from the meta agent, we perform two rounds of self-reflection to make the\\ngenerated agent novel and error-free (Madaan et al., 2024; Shinn et al., 2023).\\nPrompt for self-reflection round 1.\\n[GeneratedAgentfromPreviousIteration]\\nCarefully review the proposed new architecture and reflect on the following points:\\n1. **Interestingness**: Assess whether your proposed architecture is interesting or innovative compared\\nto existing methods in the archive. If you determine that the proposed architecture is not interesting,\\nsuggest a new architecture that addresses these shortcomings.\\n- Make sure to check the difference between the proposed architecture and previous attempts.\\n- Compare the proposal and the architectures in the archive CAREFULLY, including their actual differences\\nin the implementation.\\n- Decide whether the current architecture is innovative.\\n- USE CRITICAL THINKING!\\n2. **Implementation Mistakes**: Identify any mistakes you may have made in the implementation.\\nReview the code carefully, debug any issues you find, and provide a corrected version. REMEMBER\\nchecking \"## WRONG Implementation examples\" in the prompt.\\n3. **Improvement**: Based on the proposed architecture, suggest improvements in the detailed\\nimplementation that could increase its performance or effectiveness. In this step, focus on refining and\\noptimizing the existing implementation without altering the overall design framework, except if you\\nwant to propose a different architecture if the current is not interesting.\\n- Observe carefully about whether the implementation is actually doing what it is supposed to do.\\n- Check if there is redundant code or unnecessary steps in the implementation. Replace them with\\neffective implementation.\\n- Try to avoid the implementation being too similar to the previous agent.\\nAnd then, you need to improve or revise the implementation, or implement the new proposed architecture\\nbased on the reflection.\\nYour response should be organized as follows:\\n\"reflection\": Provide your thoughts on the interestingness of the architecture, identify any mistakes in the\\nimplementation, and suggest improvements.\\n\"thought\": Revise your previous proposal or propose a new architecture if necessary, using the same\\nformat as the example response.\\n\"name\": Provide a name for the revised or new architecture. (Don‚Äôt put words like \"new\" or \"improved\"\\nin the name.)\\n\"code\": Provide the corrected code or an improved implementation. Make sure you actually implement\\nyour fix and improvement in this code.\\n25\\nAutomated Design of Agentic Systems\\nPrompt for self-reflection round 2.\\nUsing the tips in ‚Äú## WRONG Implementation examples‚Äù section, further revise the code.\\nYour response should be organized as follows:\\nInclude your updated reflections in the ‚Äúreflection‚Äù. Repeat the previous ‚Äúthought‚Äù and ‚Äúname‚Äù. Update\\nthe corrected version of the code in the ‚Äúcode‚Äù section.\\nWhen an error is encountered during the execution of the generated code, we conduct a reflection\\nand re-run the code. This process is repeated up to five times if errors persist. Here is the prompt we\\nuse to self-reflect any runtime error:\\nPrompt for self-reflection when a runtime error occurs.\\nError during evaluation:\\n[Runtimeerrors]\\nCarefully consider where you went wrong in your latest implementation. Using insights from previous\\nattempts, try to debug the current code to implement the same thought. Repeat your previous thought in\\n‚Äúthought‚Äù, and put your thinking for debugging in ‚Äúdebug_thought‚Äù.\\nB. Framework Code\\nIn this paper, we provide the meta agent with a simple framework to implement basic functions,\\nsuch as querying Foundation Models (FMs) and formatting prompts. The framework consists of\\nfewer than 100 lines of code (excluding comments). In this framework, we encapsulate every\\npiece of information into a namedtuple Info object, making it easy to combine different types of\\ninformation (e.g., FM responses, results from tool function calls, task descriptions) and facilitate\\ncommunicationbetweendifferentmodules. Additionally,intheFMmodule,weautomaticallyconstruct\\nthe prompt by concatenating all input Info objects into a structured format, with each Info titled by\\nits metadata (e.g., name, author). Throughout the appendix, we renamed some variables in the\\ncode to match the terminologies used in the main text. The full framework code is available at\\nhttps://github.com/ShengranHu/ADAS .\\nCode 1|The simple framework used in Meta-Agent Search.\\n1# Named tuple for holding task information\\n2Info = namedtuple (‚ÄôInfo ‚Äô, [‚Äôname ‚Äô, ‚Äôauthor ‚Äô, ‚Äôcontent ‚Äô, ‚Äô\\niteration_idx ‚Äô])\\n3\\n4# Format instructions for FM response\\n5FORMAT_INST = lambda request_keys : f\" Reply EXACTLY with the\\nfollowing JSON format .\\\\n{str( request_keys )}\\\\ nDO NOT MISS ANY\\nFIELDS AND MAKE SURE THE JSON FORMAT IS CORRECT !\\\\n\"\\n6\\n7# Description of the role of the FM Module\\n8ROLE_DESC = lambda role : f\"You are a { role }.\"\\n9\\n10@backoff . on_exception ( backoff .expo , openai . RateLimitError )\\n11def get_json_response_from_gpt (msg , model , system_message ,\\ntemperature ):\\n12 \\\\\"\"\"\\n13 Function to get JSON response from GPT model .\\n14\\n15 Args :\\n16 - msg (str ): The user message .\\n26\\nAutomated Design of Agentic Systems\\n17 - model (str ): The model to use .\\n18 - system_message (str ): The system message .\\n19 - temperature ( float ): Sampling temperature .\\n20\\n21 Returns :\\n22 - dict : The JSON response .\\n23 \\\\\"\"\"\\n24 ...\\n25 return json_dict\\n26\\n27class FM_Module :\\n28 \\\\\"\"\"\\n29 Base class for an FM module .\\n30\\n31 Attributes :\\n32 - output_fields ( list ): Fields expected in the output .\\n33 - name (str ): Name of the FM module .\\n34 - role (str ): Role description for the FM module .\\n35 - model (str ): Model to be used .\\n36 - temperature ( float ): Sampling temperature .\\n37 - id (str ): Unique identifier for the FM module instance .\\n38 \\\\\"\"\"\\n39\\n40 def __init__ (self , output_fields : list , name : str , role =‚Äôhelpful\\nassistant ‚Äô, model =‚Äôgpt -3.5 - turbo -0125 ‚Äô, temperature =0.5) ->\\nNone :\\n41 ...\\n42\\n43 def generate_prompt (self , input_infos , instruction ) -> str:\\n44 \\\\\"\"\"\\n45 Generates a prompt for the FM.\\n46\\n47 Args :\\n48 - input_infos ( list ): List of input information .\\n49 - instruction (str ): Instruction for the task .\\n50\\n51 Returns :\\n52 - tuple : System prompt and user prompt .\\n53\\n54 An example of generated prompt :\\n55 \"\"\\n56 You are a helpful assistant .\\n57\\n58 # Output Format :\\n59 Reply EXACTLY with the following JSON format .\\n60 ...\\n61\\n62 # Your Task :\\n63 You will given some number of paired example inputs and\\noutputs . The outputs ...\\n64\\n65 ### thinking #1 by Chain -of - Thought hkFo ( yourself ):\\n66 ...\\n67\\n68 # Instruction :\\n69 Please think step by step and then solve the task by writing\\n27\\nAutomated Design of Agentic Systems\\nthe code .\\n70 \"\"\\n71 \\\\\"\"\"\\n72 ...\\n73 return system_prompt , prompt\\n74\\n75 def query (self , input_infos : list , instruction , iteration_idx\\n= -1) -> list [ Info ]:\\n76 \\\\\"\"\"\\n77 Queries the FM with provided input information and\\ninstruction .\\n78\\n79 Args :\\n80 - input_infos ( list ): List of input information .\\n81 - instruction (str ): Instruction for the task .\\n82 - iteration_idx (int ): Iteration index for the task .\\n83\\n84 Returns :\\n85 - output_infos ( list [ Info ]): Output information .\\n86 \\\\\"\"\"\\n87 ...\\n88 return output_infos\\n89\\n90 def __repr__ ( self ):\\n91 return f\"{ self . agent_name } { self .id}\"\\n92\\n93 def __call__ (self , input_infos : list , instruction , iteration_idx\\n= -1):\\n94 return self . query ( input_infos , instruction , iteration_idx =\\niteration_idx )\\n95\\n96class AgentSystem :\\n97 def forward (self , taskInfo ) -> Union [Info , str ]:\\n98 \\\\\"\"\"\\n99 Placeholder method for processing task information .\\n100\\n101 Args :\\n102 - taskInfo ( Info ): Task information .\\n103\\n104 Returns :\\n105 - Answer ( Union [Info , str ]): Your FINAL Answer . Return\\neither a namedtuple Info or a string for the answer .\\n106 \\\\\"\"\"\\n107 pass\\nWith the provided framework, an agent can be easily defined with a ‚Äúforward‚Äù function. Here we\\nshow an example of implementing self-reflection using the framework.\\nCode 2|Self-Reflection implementation example\\n1def forward (self , taskInfo ):\\n2 # Instruction for initial reasoning\\n3 cot_initial_instruction = \" Please think step by step and then\\nsolve the task .\"\\n4\\n5 # Instruction for reflecting on previous attempts and feedback\\n28\\nAutomated Design of Agentic Systems\\nto improve\\n6 cot_reflect_instruction = \" Given previous attempts and feedback ,\\ncarefully consider where you could go wrong in your latest\\nattempt . Using insights from previous attempts , try to solve\\nthe task better .\"\\n7 cot_module = FM_Module ([ ‚Äôthinking ‚Äô, ‚Äôanswer ‚Äô], ‚ÄôChain -of - Thought\\n‚Äô)\\n8\\n9 # Instruction for providing feedback and correcting the answer\\n10 critic_instruction = \" Please review the answer above and\\ncriticize on where might be wrong . If you are absolutely sure\\nit is correct , output ‚ÄôTrue ‚Äô in ‚Äôcorrect ‚Äô.\"\\n11 critic_module = FM_Module ([ ‚Äôfeedback ‚Äô, ‚Äôcorrect ‚Äô], ‚ÄôCritic ‚Äô)\\n12\\n13 N_max = 5 # Maximum number of attempts\\n14\\n15 # Initial attempt\\n16 cot_inputs = [ taskInfo ]\\n17 thinking , answer = cot_module ( cot_inputs ,\\ncot_initial_instruction , 0)\\n18\\n19 for i in range ( N_max ):\\n20 # Get feedback and correct status from the critic\\n21 feedback , correct = critic_module ([ taskInfo , thinking ,\\nanswer ], critic_instruction , i)\\n22 if correct . content == ‚ÄôTrue ‚Äô:\\n23 break\\n24\\n25 # Add feedback to the inputs for the next iteration\\n26 cot_inputs . extend ([ thinking , answer , feedback ])\\n27\\n28 # Reflect on previous attemps and refine the answer\\n29 thinking , answer = cot_module ( cot_inputs ,\\ncot_reflect_instruction , i + 1)\\n30 return answer\\n29\\nAutomated Design of Agentic Systems\\nExample Input -output grid #1\\nExample Input -output grid #2\\nTest grid\\nAnswer\\nFigure 4|An example task from the ARC challenge (Chollet, 2019). Given the input-output grid\\nexamples, the AI system is asked to learn the transformation rules and then apply these learned rules\\nto the test grid to predict the final answer.\\nC. Experiment Details for ARC Challenge\\nAn example task from the ARC challenge is shown in Figure 4. In the ARC challenge experiments\\n(Section 4.1), we represent the grids as strings of 2-D arrays, where each color is represented by an\\ninteger. Weinstructthemetaagenttodesignagentsthatgeneratecodeassolutionsratherthandirectly\\noutputting answers. Additionally, we provide two tool functions within the framework: (1) to test\\nwhetherthegeneratedcodecansolvetheexamplegridsand(2)toobtainthetask‚Äôsanswerbyapplying\\nthe generated code to the test grid. The accuracy rate is calculated by the Exact Match between the\\nreference solution and the predicted answer. The meta agent uses ‚Äúgpt-4o-2024-05-13‚Äù (OpenAI,\\n2024), while discovered agents and baselines are evaluated using ‚Äúgpt-3.5-turbo-0125‚Äù (OpenAI,\\n2022) to reduce compute cost.\\nThe domain description of ARC for the meta agent is shown below:\\nDescription of ARC for the meta agent.\\nYour aim is to find an optimal agent performing well on the ARC (Abstraction and Reasoning Corpus)\\nchallenge.\\nIn this challenge, each task consists of three demonstration examples, and one test example. Each\\nExample consists of an ‚Äúinput grid‚Äù and an ‚Äúoutput grid‚Äù. Test-takers need to use the transformation rule\\nlearned from the examples to predict the output grid for the test example.\\n30\\nAutomated Design of Agentic Systems\\n# An example task from ARC challenge:\\n## Task Overview:\\nYou will be given some number of paired example inputs and outputs grids. The outputs were produced\\nby applying a transformation rule to the input grids. In addition to the paired example inputs and\\noutputs, there is also one test input without a known output.\\nThe inputs and outputs are each ‚Äúgrids‚Äù. A grid is a rectangular matrix of integers between 0 and 9\\n(inclusive). Each number corresponds to a color. 0 is black.\\nYour task is to determine the transformation rule from examples and find out the answer, involving\\ndetermining the size of the output grid for the test and correctly filling each cell of the grid with the\\nappropriate color or number.\\nThe transformation only needs to be unambiguous and applicable to the example inputs and the test\\ninput. It doesn‚Äôt need to work for all possible inputs. Observe the examples carefully, imagine the grid\\nvisually, and try to find the pattern.\\n## Examples:\\n### Example 0:\\ninput = [[0,0,0,0,5,0,0,0,0], [0,0,0,0,5,0,0,0,0], [0,0,0,4,5,0,0,0,0], [0,0,0,4,5,4,4,0,0],\\n[0,0,3,3,5,0,0,0,0], [0,0,0,3,5,0,0,0,0], [0,0,0,3,5,3,3,3,0], [0,0,0,3,5,0,0,0,0], [0,0,0,0,5,0,0,0,0],\\n[0,0,0,0,5,0,0,0,0]]\\noutput = [[0,0,0,0], [0,0,0,0], [0,0,0,4], [0,0,4,4], [0,0,3,3], [0,0,0,3], [0,3,3,3], [0,0,0,3], [0,0,0,0],\\n[0,0,0,0]]\\n### Example 1:\\ninput = [[0,0,0,0,5,0,0,0,0], [0,0,0,2,5,0,0,0,0], [0,0,0,2,5,2,6,0,0], [0,0,0,2,5,0,0,0,0],\\n[0,0,0,2,5,2,2,2,0], [0,0,6,6,5,6,0,0,0], [0,0,0,2,5,0,0,0,0], [0,2,2,0,5,2,0,0,0], [0,0,0,2,5,0,0,0,0],\\n[0,0,0,0,5,0,0,0,0]]\\noutput = [[0,0,0,0], [0,0,0,2], [0,0,6,2], [0,0,0,2], [0,2,2,2], [0,0,6,6], [0,0,0,2], [0,2,2,2], [0,0,0,2],\\n[0,0,0,0]]\\n### Example 2:\\ninput = [[0,0,0,0,5,0,0,0,0], [0,0,0,0,5,7,0,0,0], [0,0,0,8,5,0,0,0,0], [0,0,0,8,5,0,0,0,0],\\n[0,7,8,8,5,0,0,0,0], [0,0,0,0,5,8,8,0,0], [0,0,0,8,5,0,0,0,0], [0,0,0,8,5,0,0,0,0], [0,0,0,0,5,8,7,0,0],\\n[0,0,0,0,5,0,0,0,0]]\\noutput= [[0,0,0,0], [0,0,0,7], [0,0,0,8], [0,0,0,8], [0,7,8,8], [0,0,8,8], [0,0,0,8], [0,0,0,8], [0,0,7,8],\\n[0,0,0,0]]\\n### Test Problem:\\ninput = [[0,0,0,0,5,0,0,0,0], [0,0,0,1,5,0,0,0,0], [0,0,0,1,5,1,0,0,0], [0,1,1,1,5,1,1,1,6],\\n[0,0,0,6,5,6,6,0,0], [0,0,0,0,5,1,1,1,0], [0,0,0,1,5,0,0,0,0], [0,0,0,1,5,1,6,0,0], [0,0,0,0,5,6,0,0,0],\\n[0,0,0,0,5,0,0,0,0]]\\nAnalyze the transformation rules based on the provided Examples and determine what the output should\\nbe for the Test Problem.\\nHere we present the best agent on ARC discovered by Meta Agent Search. All agents from the\\nexperiment can be found at https://github.com/ShengranHu/ADAS .\\nCode 3|The best agent on ARC discovered by Meta Agent Search\\n1# Structured Feedback and Ensemble Agent\\n2def forward (self , taskInfo ):\\n3 # Step 1: Generate initial candidate solutions using multiple FM\\nModules\\n31\\nAutomated Design of Agentic Systems\\n4 initial_instruction = ‚ÄôPlease think step by step and then solve\\nthe task by writing the code .‚Äô\\n5 num_candidates = 5 # Number of initial candidates\\n6 initial_module = [ FM_Module ([ ‚Äôthinking ‚Äô, ‚Äôcode ‚Äô], ‚ÄôInitial\\nSolution ‚Äô, temperature =0.8) for _ in range ( num_candidates )]\\n7\\n8 initial_solutions = []\\n9 for i in range ( num_candidates ):\\n10 thoughts = initial_module [i ]([ taskInfo ], initial_instruction\\n)\\n11 thinking , code = thoughts [0] , thoughts [1]\\n12 feedback , correct_examples , wrong_examples = self .\\nrun_examples_and_get_feedback ( code )\\n13 if len ( correct_examples ) > 0: # Only consider solutions\\nthat passed at least one example\\n14 initial_solutions . append ({ ‚Äôthinking ‚Äô: thinking , ‚Äôcode ‚Äô:\\ncode , ‚Äôfeedback ‚Äô: feedback , ‚Äô correct_count ‚Äô: len (\\ncorrect_examples )})\\n15\\n16 # Step 2: Simulate human - like feedback for each candidate\\nsolution\\n17 human_like_feedback_module = FM_Module ([ ‚Äôthinking ‚Äô, ‚Äôfeedback ‚Äô],\\n‚ÄôHuman - like Feedback ‚Äô, temperature =0.5)\\n18 human_feedback_instruction = ‚ÄôPlease provide human - like feedback\\nfor the code , focusing on common mistakes , heuristic\\ncorrections , and best practices .‚Äô\\n19\\n20 for sol in initial_solutions :\\n21 thoughts = human_like_feedback_module ([ taskInfo , sol[‚Äô\\nthinking ‚Äô], sol[‚Äôcode ‚Äô]], human_feedback_instruction )\\n22 human_thinking , human_feedback = thoughts [0] , thoughts [1]\\n23 sol [‚Äô human_feedback ‚Äô] = human_feedback\\n24\\n25 # Step 3: Assign expert advisors to evaluate and provide\\ntargeted feedback\\n26 expert_roles = [‚ÄôEfficiency Expert ‚Äô, ‚Äô Readability Expert ‚Äô, ‚Äô\\nSimplicity Expert ‚Äô]\\n27 expert_advisors = [ FM_Module ([ ‚Äôthinking ‚Äô, ‚Äôfeedback ‚Äô], role ,\\ntemperature =0.6) for role in expert_roles ]\\n28 expert_instruction = ‚ÄôPlease evaluate the given code and provide\\ntargeted feedback for improvement .‚Äô\\n29\\n30 for sol in initial_solutions :\\n31 sol_feedback = {}\\n32 for advisor in expert_advisors :\\n33 thoughts = advisor ([ taskInfo , sol[‚Äôthinking ‚Äô], sol[‚Äôcode\\n‚Äô]], expert_instruction )\\n34 thinking , feedback = thoughts [0] , thoughts [1]\\n35 sol_feedback [ advisor . role ] = feedback\\n36 sol [‚Äô expert_feedback ‚Äô] = sol_feedback\\n37\\n38 # Step 4: Parse and structure the feedback to avoid redundancy\\nand refine the solutions iteratively\\n39 max_refinement_iterations = 3\\n40 refinement_module = FM_Module ([ ‚Äôthinking ‚Äô, ‚Äôcode ‚Äô], ‚ÄôRefinement\\nModule ‚Äô, temperature =0.5)\\n32\\nAutomated Design of Agentic Systems\\n41 refined_solutions = []\\n42\\n43 for sol in initial_solutions :\\n44 for i in range ( max_refinement_iterations ):\\n45 combined_feedback = sol[‚Äôfeedback ‚Äô]. content + sol [‚Äô\\nhuman_feedback ‚Äô]. content + ‚Äô‚Äô. join ([ fb. content for fb\\nin sol [‚Äô expert_feedback ‚Äô]. values () ])\\n46 structured_feedback = ‚Äô ‚Äô. join (set( combined_feedback .\\nsplit ())) # Avoid redundancy\\n47 refinement_instruction = ‚ÄôUsing the structured feedback ,\\nrefine the solution to improve its performance .‚Äô\\n48 thoughts = refinement_module ([ taskInfo , sol[‚Äôthinking ‚Äô],\\nsol[‚Äôcode ‚Äô], Info (‚Äôfeedback ‚Äô, ‚ÄôStructured Feedback ‚Äô,\\nstructured_feedback , i)], refinement_instruction , i)\\n49 refinement_thinking , refined_code = thoughts [0] ,\\nthoughts [1]\\n50 feedback , correct_examples , wrong_examples = self .\\nrun_examples_and_get_feedback ( refined_code )\\n51 if len ( correct_examples ) > 0:\\n52 sol. update ({ ‚Äôthinking ‚Äô: refinement_thinking , ‚Äôcode ‚Äô:\\nrefined_code , ‚Äôfeedback ‚Äô: feedback , ‚Äô\\ncorrect_count ‚Äô: len( correct_examples )})\\n53 refined_solutions . append ( sol)\\n54\\n55 # Step 5: Select the best - performing solutions and make a final\\ndecision using an ensemble approach\\n56 sorted_solutions = sorted ( refined_solutions , key= lambda x: x[‚Äô\\ncorrect_count ‚Äô], reverse = True )\\n57 top_solutions = sorted_solutions [:3] # Select the top 3\\nsolutions\\n58\\n59 final_decision_instruction = ‚ÄôGiven all the above solutions ,\\nreason over them carefully and provide a final answer by\\nwriting the code .‚Äô\\n60 final_decision_module = refinement_module ([ ‚Äôthinking ‚Äô, ‚Äôcode ‚Äô],\\n‚ÄôFinal Decision Module ‚Äô, temperature =0.1)\\n61 final_inputs = [ taskInfo ] + [ item for solution in top_solutions\\nfor item in [ solution [‚Äôthinking ‚Äô], solution [‚Äôcode ‚Äô], solution\\n[‚Äôfeedback ‚Äô]]]\\n62 final_thoughts = final_decision_module ( final_inputs ,\\nfinal_decision_instruction )\\n63 final_thinking , final_code = final_thoughts [0] , final_thoughts\\n[1]\\n64 answer = self . get_test_output_from_code ( final_code )\\n65 return answer\\nD. Experiment Details for Reasoning and Problem-Solving Domains\\nTo reduce costs during search and evaluation, we sample subsets of data from each domain. For GPQA\\n(Science), the validation set consists of 32 questions, while the remaining 166 questions form the\\ntest set. For the other domains, the validation and test sets are sampled with 128 and 800 questions,\\nrespectively. We evaluate agents five times for GPQA and once for the other domains to maintain a\\nconsistent total number of evaluations. Each domain uses zero-shot style questions, except DROP\\n(Reading Comprehension), which uses one-shot style questions following the practice in (OpenAI,\\n33\\nAutomated Design of Agentic Systems\\n2023). The meta agent uses ‚Äúgpt-4o-2024-05-13‚Äù (OpenAI, 2024), while discovered agents and\\nbaselines are evaluated using ‚Äúgpt-3.5-turbo-0125‚Äù (OpenAI, 2022) to reduce compute cost.\\nWe present the description of each domain we provide to the meta agent.\\nDescription of DROP (Reading Comprehension).\\nYour aim is to find an optimal agent performing well on the Reading Comprehension Benchmark\\nRequiring Discrete Reasoning Over Paragraphs (DROP), which assesses the ability to perform discrete\\nreasoning and comprehend detailed information across multiple paragraphs.\\n## An example question from DROP:\\nYou will be asked to read a passage and answer a question.\\nPassage:\\nNon-nationals make up more than half of the population of Bahrain, with immigrants making up\\nabout 55% of the overall population. Of those, the vast majority come from South and Southeast Asia:\\naccording to various media reports and government statistics dated between 2005-2009 roughly 290,000\\nIndians, 125,000 Bangladeshis, 45,000 Pakistanis, 45,000 Filipinos, and 8,000 Indonesians.\\nQuestion: What two nationalities had the same number of people living in Bahrain between\\n2005-2009?\\nAnswer [Not Given]: Pakistanis and Filipinos\\nDescription of GPQA (Science) for the meta agent.\\nYour aim is to find an optimal agent performing well on the GPQA (Graduate-Level Google-Proof Q&A\\nBenchmark). This benchmark consists of challenging multiple-choice questions across the domains of\\nbiology, physics, and chemistry, designed by domain experts to ensure high quality and difficulty.\\n## An example question from GPQA:\\nTwo quantum states with energies E1 and E2 have a lifetime of 10‚àí9sec and 10‚àí8sec, respectively. We\\nwant to clearly distinguish these two energy levels. Which one of the following options could be their\\nenergy difference so that they be clearly resolved?\\nAnswer choices:\\n10‚àí9eV\\n10‚àí8eV\\n10‚àí7eV\\n10‚àí6eV\\nCorrect answer [Not provided]:\\n10‚àí7eV\\nExplanation [Not provided]:\\nAccording to the uncertainty principle, Delta E* Delta t=hbar/2. Delta t is the lifetime and Delta E is the\\nwidth of the energy level. With Delta t= 10‚àí9s== >Delta E1= 3.3 10‚àí7ev. And Delta t= 10‚àí11s gives\\nDelta E2= 3.310‚àí8eV. Therefore, the energy difference between the two states must be significantly\\ngreater than 10‚àí7ev. So the answer is 10‚àí4ev.\\n34\\nAutomated Design of Agentic Systems\\nDescription of MGSM (Math) for the meta agent.\\nYour aim is to find an optimal agent performing well on the Multilingual Grade School Math Benchmark\\n(MGSM) which evaluates mathematical problem-solving abilities across various languages to ensure\\nbroad and effective multilingual performance.\\n## An example question from MGSM:\\n**Question**:„Åì„ÅÆÊï∞Â≠¶„ÅÆÂïèÈ°å„ÇíËß£„ÅÑ„Å¶„Åè„Å†„Åï„ÅÑ „ÄÇ\\nËøëÊâÄ„Åß„ÅØ„ÄÅ„Éö„ÉÉ„Éà„ÅÆ„Ç¶„Çµ„ÇÆ„ÅÆÊï∞„Åå„Éö„ÉÉ„Éà„ÅÆÁä¨„Å®Áå´„ÇíÂêà„Çè„Åõ„ÅüÊï∞„Çà„Çä„ÇÇ12ÂåπÂ∞ë„Å™„ÅÑ„ÄÇÁä¨1Âåπ„ÅÇ„Åü„Çä2Âåπ\\n„ÅÆÁå´„Åå„Åä„Çä„ÄÅÁä¨„ÅÆÊï∞„ÅØ60Âåπ„Å†„Å®„Åô„Çã„Å® „ÄÅÂÖ®ÈÉ®„ÅßËøëÊâÄ„Å´„ÅØ‰ΩïÂåπ„ÅÆ„Éö„ÉÉ„Éà„Åå„ÅÑ„Åæ„Åô„Åã Ôºü\\n**Answer (Not Given)**: 348\\nDescription of MMLU (Mult-task) for the meta agent.\\nYour aim is to find an optimal agent performing well on the MMLU (Massive Multitask Language\\nUnderstanding) benchmark, a challenging evaluation that assesses a model‚Äôs ability to answer questions\\nacross a wide range of subjects and difficulty levels. It includes subjects from STEM, social sciences,\\nhumanities, and more.\\n## An example question from MMLU:\\nAnswer the following multiple-choice question.\\nThe constellation ... is a bright W-shaped constellation in the northern sky.\\n(A) Centaurus\\n(B) Cygnus\\n(C) Cassiopeia\\n(D) Cepheus\\nE. Baselines\\nIn this paper, we implement five state-of-the-art hand-designed agent baselines for experiments\\non ARC (Section 4.1): (1) Chain-of-Thought (COT) (Wei et al., 2022), (2) Self-Consistency with\\nChain-of-Thought (COT-SC)(Wang et al., 2023b), (3) Self-Refine (Madaan et al., 2024; Shinn et al.,\\n2023), (4) LLM-Debate (Du et al., 2023), and (5) Quality-Diversity, a simplified version of Intelligent\\nGo-Explore (Lu et al., 2024c).\\nIn addition to these baselines, we implement two more for experiments on Reasoning and\\nProblem-Solving domains (Section 4.2): (6) Step-back Abstraction (Zheng et al., 2023) and (7)\\nRole Assignment (Xu et al., 2023). An example implementation of Self-Refine with our simple\\nframework is shown in Appendix B. Detailed implementations of all baselines can be found at\\nhttps://github.com/ShengranHu/ADAS .\\nIn COT, we prompt the FM to think step by step before answering the question. In COT-SC, we\\nsample ùëÅ=5answers and then perform an ensemble using either majority voting or an FM query.\\nIn Self-Refine, we allow up to five refinement iterations, with an early stop if the critic deems the\\nanswer correct. In LLM-Debate, each debate module is assigned a unique role, such as Physics Expert\\nor Chemistry Expert, and the debate lasts for two rounds. In Quality-Diversity, we conduct three\\n35\\nAutomated Design of Agentic Systems\\niterations to collect diverse answers based on previously proposed ones. In Role Assignment, we use\\nan FM query to first choose a role from a predefined set, and then use another FM query to answer\\nthe question by acting within the chosen role.\\nF. Example Agents\\nIn this section, we present the detailed implementation of three example discovered agents by Meta\\nAgent Search shown in Figure 1. The ‚ÄúMulti-Step Peer Review Agent‚Äù and ‚ÄúDivide and Conquer Agent‚Äù\\nwere discovered during the search in the Reading Comprehension domain (GPQA) (Rein et al., 2023),\\nwhile the ‚ÄúVerified Multimodal Agent‚Äù was discovered during the search in the Math domain (MGSM)\\n(Shietal.,2023). Alldiscoveredagentscanbefoundat https://github.com/ShengranHu/ADAS .\\nCode 4|Example discovered agent: Multi-Step Peer Review Agent\\n1def forward (self , taskInfo ):\\n2 initial_instruction = \" Please think step by step and then solve\\nthe task .\"\\n3 critique_instruction = \" Please review the answer above and\\nprovide feedback on where it might be wrong . If you are\\nabsolutely sure it is correct , output ‚ÄôTrue ‚Äô in ‚Äôcorrect ‚Äô.\"\\n4 refine_instruction = \" Given previous attempts and feedback ,\\ncarefully consider where you could go wrong in your latest\\nattempt . Using insights from previous attempts , try to solve\\nthe task better .\"\\n5 final_decision_instruction = \" Given all the above thinking and\\nanswers , reason over them carefully and provide a final\\nanswer .\"\\n6\\n7 FM_modules = [ FM_module ([ ‚Äôthinking ‚Äô, ‚Äôanswer ‚Äô], ‚ÄôFM Module ‚Äô,\\nrole = role ) for role in [‚ÄôPhysics Expert ‚Äô, ‚ÄôChemistry Expert ‚Äô,\\n‚ÄôBiology Expert ‚Äô, ‚ÄôScience Generalist ‚Äô]]\\n8 critic_modules = [ FM_module ([ ‚Äôfeedback ‚Äô, ‚Äôcorrect ‚Äô], ‚ÄôCritic ‚Äô,\\nrole = role ) for role in [‚ÄôPhysics Critic ‚Äô, ‚ÄôChemistry Critic ‚Äô,\\n‚ÄôBiology Critic ‚Äô, ‚ÄôGeneral Critic ‚Äô]]\\n9 final_decision_module = FM_module ([ ‚Äôthinking ‚Äô, ‚Äôanswer ‚Äô], ‚ÄôFinal\\nDecision ‚Äô, temperature =0.1)\\n10\\n11 all_thinking = [[] for _ in range (len( FM_modules ))]\\n12 all_answer = [[] for _ in range (len( FM_modules ))]\\n13 all_feedback = [[] for _ in range (len( FM_modules ))]\\n14\\n15 for i in range (len( FM_modules )):\\n16 thinking , answer = FM_modules [i]([ taskInfo ],\\ninitial_instruction )\\n17 all_thinking [i]. append ( thinking )\\n18 all_answer [i]. append ( answer )\\n19\\n20 for i in range (len( FM_modules )):\\n21 for j in range (len( FM_modules )):\\n22 if i != j:\\n23 feedback , correct = critic_modules [j]([ taskInfo ,\\nall_thinking [i][0] , all_answer [i][0]] ,\\ncritique_instruction )\\n24 all_feedback [i]. append ( feedback )\\n25\\n36\\nAutomated Design of Agentic Systems\\n26 for i in range (len( FM_modules )):\\n27 refine_inputs = [ taskInfo , all_thinking [i][0] , all_answer [i\\n][0]] + all_feedback [i]\\n28 thinking , answer = FM_modules [i]( refine_inputs ,\\nrefine_instruction )\\n29 all_thinking [i]. append ( thinking )\\n30 all_answer [i]. append ( answer )\\n31\\n32 final_inputs = [ taskInfo ] + [ all_thinking [i ][1] for i in range (\\nlen( FM_modules ))] + [ all_answer [i ][1] for i in range (len(\\nFM_modules ))]\\n33 thinking , answer = final_decision_module ( final_inputs ,\\nfinal_decision_instruction )\\n34\\n35 return answer\\nCode 5|Example discovered agent: Divide and Conquer Agent\\n1def forward (self , taskInfo ):\\n2 # Step 1: Decompose the problem into sub - problems\\n3 decomposition_instruction = \" Please decompose the problem into\\nsmaller , manageable sub - problems . List each sub - problem\\nclearly .\"\\n4 decomposition_module = FM_Module ([ ‚Äôthinking ‚Äô, ‚Äô sub_problems ‚Äô], ‚Äô\\nDecomposition Module ‚Äô)\\n5\\n6 # Step 2: Assign each sub - problem to a specialized expert\\n7 sub_problem_instruction = \" Please think step by step and then\\nsolve the sub - problem .\"\\n8 specialized_experts = [ FM_Module ([ ‚Äôthinking ‚Äô, ‚Äô sub_solution ‚Äô], ‚Äô\\nSpecialized Expert ‚Äô, role = role ) for role in [‚ÄôPhysics Expert ‚Äô\\n, ‚ÄôChemistry Expert ‚Äô, ‚ÄôBiology Expert ‚Äô, ‚ÄôGeneral Expert ‚Äô]]\\n9\\n10 # Step 3: Integrate the sub - problem solutions into the final\\nanswer\\n11 integration_instruction = \" Given the solutions to the sub -\\nproblems , integrate them to provide a final answer to the\\noriginal problem .\"\\n12 integration_module = FM_Module ([ ‚Äôthinking ‚Äô, ‚Äôanswer ‚Äô], ‚Äô\\nIntegration Module ‚Äô, temperature =0.1)\\n13\\n14 # Decompose the problem\\n15 thinking , sub_problems = decomposition_module ([ taskInfo ],\\ndecomposition_instruction )\\n16\\n17 # Ensure sub_problems is a string and split into individual sub -\\nproblems\\n18 sub_problems_list = sub_problems . content . split (‚Äô\\\\n‚Äô) if\\nisinstance ( sub_problems . content , str) else []\\n19\\n20 # Solve each sub - problem\\n21 sub_solutions = []\\n22 for i, sub_problem in enumerate ( sub_problems_list ):\\n23 sub_problem_info = Info (‚Äô sub_problem ‚Äô, decomposition_module .\\n__repr__ () , sub_problem , i)\\n24 sub_thinking , sub_solution = specialized_experts [i % len (\\n37\\nAutomated Design of Agentic Systems\\nspecialized_experts )]([ sub_problem_info ],\\nsub_problem_instruction )\\n25 sub_solutions . append ( sub_solution )\\n26\\n27 # Integrate the sub - problem solutions\\n28 integration_inputs = [ taskInfo ] + sub_solutions\\n29 thinking , answer = integration_module ( integration_inputs ,\\nintegration_instruction )\\n30\\n31 return answer\\nCode 6|Example discovered agent: Verified Multimodal Agent\\n1def forward (self , taskInfo ):\\n2 # Instruction for generating visual representation of the\\nproblem\\n3 visual_instruction = \" Please create a visual representation (e.g\\n., diagram , graph ) of the given problem .\"\\n4\\n5 # Instruction for verifying the visual representation\\n6 verification_instruction = \" Please verify the accuracy and\\nrelevance of the visual representation . Provide feedback and\\nsuggestions for improvement if necessary .\"\\n7\\n8 # Instruction for solving the problem using the verified visual\\naid\\n9 cot_instruction = \" Using the provided visual representation ,\\nthink step by step and solve the problem .\"\\n10\\n11 # Instantiate the visual representation module , verification\\nmodule , and Chain -of - Thought module\\n12 visual_module = FM_Module ([ ‚Äôvisual ‚Äô], ‚ÄôVisual Representation\\nModule ‚Äô)\\n13 verification_module = FM_Module ([ ‚Äôfeedback ‚Äô, ‚Äô verified_visual ‚Äô],\\n‚Äô Verification Module ‚Äô)\\n14 cot_module = FM_Module ([ ‚Äôthinking ‚Äô, ‚Äôanswer ‚Äô], ‚ÄôChain -of - Thought\\nModule ‚Äô)\\n15\\n16 # Generate the visual representation of the problem\\n17 visual_output = visual_module ([ taskInfo ], visual_instruction )\\n18 visual_representation = visual_output [0] # Using Info object\\ndirectly\\n19\\n20 # Verify the visual representation\\n21 feedback , verified_visual = verification_module ([ taskInfo ,\\nvisual_representation ], verification_instruction )\\n22\\n23 # Use the verified visual representation to solve the problem\\n24 thinking , answer = cot_module ([ taskInfo , verified_visual ],\\ncot_instruction )\\n25 return answer\\n38\\nAutomated Design of Agentic Systems\\nG. Cost of Experiments\\nA single run of search and evaluation on ARC (Section 4.1) costs approximately $500 USD in OpenAI\\nAPI costs, while a run within the reasoning and problem-solving domains (Section 4.2) costs about\\n$300 USD.\\nThe primary expense comes from querying the ‚Äúgpt-3.5-turbo-0125‚Äù model during the evaluation\\nof discovered agents. Notably, the latest GPT-4 model, ‚Äúgpt-4o-mini,‚Äù is less than one-third the price\\nof ‚Äúgpt-3.5-turbo-0125‚Äù and offers better performance, suggesting that we could achieve improved\\nresults with Meta Agent Search at just one-third of the cost. Additionally, as discussed in Section 6, the\\ncurrent naive evaluation function is both expensive and overlooks valuable information. We anticipate\\nthat future work adopting more sophisticated evaluation functions could significantly reduce the cost\\nof ADAS algorithms.\\n39']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV-tj5WFR6yu",
        "outputId": "674eb315-1ff3-4597-bcf5-38ece0a812ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-8-19\n",
            "Automated Design of Agentic Systems\n",
            "Shengran Hu1,2, Cong Lu1,2and Jeff Clune1,2,3\n",
            "1University of British Columbia,2Vector Institute,3Canada \n"
          ]
        }
      ],
      "source": [
        "print(documents[0][:150])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHlTvCzYR6yu"
      },
      "source": [
        "### Splitting Text Into Chunks\n",
        "\n",
        "As we can see, there is one massive document.\n",
        "\n",
        "We'll want to chunk the document into smaller parts so it's easier to pass the most relevant snippets to the LLM.\n",
        "\n",
        "There is no fixed way to split/chunk documents - and you'll need to rely on some intuition as well as knowing your data *very* well in order to build the most robust system.\n",
        "\n",
        "For this toy example, we'll just split blindly on length.\n",
        "\n",
        ">There's an opportunity to clear up some terminology here, for this course we will be stick to the following:\n",
        ">\n",
        ">- \"source documents\" : The `.txt`, `.pdf`, `.html`, ..., files that make up the files and information we start with in its raw format\n",
        ">- \"document(s)\" : single (or more) text object(s)\n",
        ">- \"corpus\" : the combination of all of our documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G6Voc0jR6yv"
      },
      "source": [
        "As you can imagine (though it's not specifically true in this toy example) the idea of splitting documents is to break them into managable sized chunks that retain the most relevant local context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMC4tsEmR6yv",
        "outputId": "08689c0b-57cd-4040-942a-8193e997f5cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "137"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_splitter = CharacterTextSplitter()\n",
        "split_documents = text_splitter.split_texts(documents)\n",
        "len(split_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2wKT0WLR6yv"
      },
      "source": [
        "Let's take a look at some of the documents we've managed to split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcYMwWJoR6yv",
        "outputId": "20d69876-feca-4826-b4be-32915276987a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['2024-8-19\\nAutomated Design of Agentic Systems\\nShengran Hu1,2, Cong Lu1,2and Jeff Clune1,2,3\\n1University of British Columbia,2Vector Institute,3Canada CIFAR AI Chair\\nResearchers are investing substantial effort in developing powerful general-purpose agents, wherein\\nFoundation Models are used as modules within agentic systems (e.g. Chain-of-Thought, Self-Reflection,\\nToolformer). However, the history of machine learning teaches us that hand-designed solutions are\\neventually replaced by learned solutions. We formulate a new research area, Automated Design of\\nAgentic Systems (ADAS), which aims to automatically create powerful agentic system designs, including\\ninventing novel building blocks and/or combining them in new ways. We further demonstrate that there\\nis an unexplored yet promising approach within ADAS where agents can be defined in code and new\\nagents can be automatically discovered by a meta agent programming ever better ones in code. Given\\nthat programming languages are Turing Com',\n",
              " 'ach within ADAS where agents can be defined in code and new\\nagents can be automatically discovered by a meta agent programming ever better ones in code. Given\\nthat programming languages are Turing Complete, this approach theoretically enables the learning\\nofany possible agentic system: including novel prompts, tool use, control flows, and combinations\\nthereof. We present a simple yet effective algorithm named Meta Agent Search to demonstrate this idea,\\nwhere a meta agent iteratively programs interesting new agents based on an ever-growing archive of\\nprevious discoveries. Through extensive experiments across multiple domains including coding, science,\\nand math, we show that our algorithm can progressively invent agents with novel designs that greatly\\noutperform state-of-the-art hand-designed agents. Importantly, we consistently observe the surprising\\nresult that agents invented by Meta Agent Search maintain superior performance even when transferred\\nacross domains and models, demonstrat']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_documents[0:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOU-RFP_R6yv"
      },
      "source": [
        "## Task 3: Embeddings and Vectors\n",
        "\n",
        "Next, we have to convert our corpus into a \"machine readable\" format as we explored in the Embedding Primer notebook.\n",
        "\n",
        "Today, we're going to talk about the actual process of creating, and then storing, these embeddings, and how we can leverage that to intelligently add context to our queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### OpenAI API Key\n",
        "\n",
        "In order to access OpenAI's APIs, we'll need to provide our OpenAI API Key!\n",
        "\n",
        "You can work through the folder \"OpenAI API Key Setup\" for more information on this process if you don't already have an API Key!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from getpass import getpass\n",
        "\n",
        "openai.api_key = getpass(\"OpenAI API Key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vector Database\n",
        "\n",
        "Let's set up our vector database to hold all our documents and their embeddings!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDQrfAR1R6yv"
      },
      "source": [
        "While this is all baked into 1 call - we can look at some of the code that powers this process to get a better understanding:\n",
        "\n",
        "Let's look at our `VectorDatabase().__init__()`:\n",
        "\n",
        "```python\n",
        "def __init__(self, embedding_model: EmbeddingModel = None):\n",
        "        self.vectors = defaultdict(np.array)\n",
        "        self.embedding_model = embedding_model or EmbeddingModel()\n",
        "```\n",
        "\n",
        "As you can see - our vectors are merely stored as a dictionary of `np.array` objects.\n",
        "\n",
        "Secondly, our `VectorDatabase()` has a default `EmbeddingModel()` which is a wrapper for OpenAI's `text-embedding-3-small` model.\n",
        "\n",
        "> **Quick Info About `text-embedding-3-small`**:\n",
        "> - It has a context window of **8191** tokens\n",
        "> - It returns vectors with dimension **1536**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L273pRdeR6yv"
      },
      "source": [
        "#### ‚ùìQuestion #1:\n",
        "\n",
        "The default embedding dimension of `text-embedding-3-small` is 1536, as noted above. \n",
        "\n",
        "1. Is there any way to modify this dimension?\n",
        "    Yes, it is posible change the dimension of the vectors.it  can done that by setting the `dimension` parameter in the `EmbeddingModel`\n",
        "2. What technique does OpenAI use to achieve this?\n",
        "\n",
        "    It uses a technique called [PCA] or [SVD] to reduce the dimension of the vectors.\n",
        "\n",
        "\n",
        "\n",
        "> NOTE: Check out this [API documentation](https://platform.openai.com/docs/api-reference/embeddings/create) for the answer to question #1, and [this documentation](https://platform.openai.com/docs/guides/embeddings/use-cases) for an answer to question #2!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5FZY7K3R6yv"
      },
      "source": [
        "We can call the `async_get_embeddings` method of our `EmbeddingModel()` on a list of `str` and receive a list of `float` back!\n",
        "\n",
        "```python\n",
        "async def async_get_embeddings(self, list_of_text: List[str]) -> List[List[float]]:\n",
        "        return await aget_embeddings(\n",
        "            list_of_text=list_of_text, engine=self.embeddings_model_name\n",
        "        )\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSct6X0aR6yv"
      },
      "source": [
        "We cast those to `np.array` when we build our `VectorDatabase()`:\n",
        "\n",
        "```python\n",
        "async def abuild_from_list(self, list_of_text: List[str]) -> \"VectorDatabase\":\n",
        "        embeddings = await self.embedding_model.async_get_embeddings(list_of_text)\n",
        "        for text, embedding in zip(list_of_text, embeddings):\n",
        "            self.insert(text, np.array(embedding))\n",
        "        return self\n",
        "```\n",
        "\n",
        "And that's all we need to do!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "O4KoLbVDR6yv"
      },
      "outputs": [],
      "source": [
        "vector_db = VectorDatabase()\n",
        "vector_db = asyncio.run(vector_db.abuild_from_list(split_documents))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSZwaGvpR6yv"
      },
      "source": [
        "#### ‚ùìQuestion #2:\n",
        "\n",
        "What are the benefits of using an `async` approach to collecting our embeddings?\n",
        "\n",
        "¬¥Using async, we can collect our embeddings in parallel! thanks to the concurrency of asyncio.¬¥\n",
        "\n",
        "> NOTE: Determining the core difference between `async` and `sync` will be useful! If you get stuck - ask ChatGPT!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRBdIt-xR6yw"
      },
      "source": [
        "So, to review what we've done so far in natural language:\n",
        "\n",
        "1. We load source documents\n",
        "2. We split those source documents into smaller chunks (documents)\n",
        "3. We send each of those documents to the `text-embedding-3-small` OpenAI API endpoint\n",
        "4. We store each of the text representations with the vector representations as keys/values in a dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-vWANZyR6yw"
      },
      "source": [
        "### Semantic Similarity\n",
        "\n",
        "The next step is to be able to query our `VectorDatabase()` with a `str` and have it return to us vectors and text that is most relevant from our corpus.\n",
        "\n",
        "We're going to use the following process to achieve this in our toy example:\n",
        "\n",
        "1. We need to embed our query with the same `EmbeddingModel()` as we used to construct our `VectorDatabase()`\n",
        "2. We loop through every vector in our `VectorDatabase()` and use a distance measure to compare how related they are\n",
        "3. We return a list of the top `k` closest vectors, with their text representations\n",
        "\n",
        "There's some very heavy optimization that can be done at each of these steps - but let's just focus on the basic pattern in this notebook.\n",
        "\n",
        "> We are using [cosine similarity](https://www.engati.com/glossary/cosine-similarity) as a distance metric in this example - but there are many many distance metrics you could use - like [these](https://flavien-vidal.medium.com/similarity-distances-for-natural-language-processing-16f63cd5ba55)\n",
        "\n",
        "> We are using a rather inefficient way of calculating relative distance between the query vector and all other vectors - there are more advanced approaches that are much more efficient, like [ANN](https://towardsdatascience.com/comprehensive-guide-to-approximate-nearest-neighbors-algorithms-8b94f057d6b6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76d96uavR6yw",
        "outputId": "bbfccc31-20a2-41c7-c14d-46554a43ed2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('2024-8-19\\nAutomated Design of Agentic Systems\\nShengran Hu1,2, Cong Lu1,2and Jeff Clune1,2,3\\n1University of British Columbia,2Vector Institute,3Canada CIFAR AI Chair\\nResearchers are investing substantial effort in developing powerful general-purpose agents, wherein\\nFoundation Models are used as modules within agentic systems (e.g. Chain-of-Thought, Self-Reflection,\\nToolformer). However, the history of machine learning teaches us that hand-designed solutions are\\neventually replaced by learned solutions. We formulate a new research area, Automated Design of\\nAgentic Systems (ADAS), which aims to automatically create powerful agentic system designs, including\\ninventing novel building blocks and/or combining them in new ways. We further demonstrate that there\\nis an unexplored yet promising approach within ADAS where agents can be defined in code and new\\nagents can be automatically discovered by a meta agent programming ever better ones in code. Given\\nthat programming languages are Turing Com',\n",
              "  0.7372905471767706),\n",
              " ('\\nAutomated Design of Agentic Systems\\nSearch Space\\nE.g. Agents defined by code\\nSearch Algorithm\\nE.g. LLM defines agents using code\\nEvaluation Function\\nE.g. Accuracy on the taskWhere is the capital of CanadaOttawa\\n‚úÖSampleNew AgentEvaluate the ObjectivesAgent‚Ä¶‚Ä¶1 + 1 = ?\\nFigure 2|The three key components of Automated Design of Agentic Systems (ADAS). The search\\nspace determines which agentic systems can be represented in ADAS. The search algorithm specifies\\nhow the ADAS method explores the search space. The evaluation function defines how to evaluate a\\ncandidate agent on target objectives such as performance.\\nFormulation\\nAutomated Design of Agentic Systems (ADAS) involves using a search algorithm to discover\\nagentic systems across a search space thatoptimize anevaluation function .\\n‚Ä¢Search Space : The search space defines which agentic systems can be represented and thus\\ndiscovered in ADAS. For example, works like PromptBreeder (Fernando et al., 2024) mutate only\\nthe text prompts of an age',\n",
              "  0.7169430937648112),\n",
              " ('; and\\nan endless number of robotics learning environments can be automatically generated in works like\\nOMNI-EPIC (Faldor et al., 2024), which demonstrate surprising creativity in generated environments\\nand allow more efficient environment creation than the manual approach (see more examples in\\nSection 5). Therefore, in this paper, we propose a new research question: Can we automate the design\\nof agentic systems rather than relying on manual efforts?\\nTo explore the above research question, we formulate a new research area we call Automated\\nDesign of AgenticSystems (ADAS), which aims to automatically invent novel building blocks and\\ndesign powerful agentic systems (Section 2). We argue that ADAS may prove to be the fastest path to\\ndeveloping powerful agents, and show initial evidence that learned agents can greatly outperform\\nhand-designed agents. Considering the tremendous number of building blocks yet to be discovered in\\nagentic systems (Section 5), it would take a long time for our re',\n",
              "  0.7066410631424915)]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_db.search_by_text(\"What is Automated Design of Agentic Systems ?\", k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TehsfIiKR6yw"
      },
      "source": [
        "## Task 4: Prompts\n",
        "\n",
        "In the following section, we'll be looking at the role of prompts - and how they help us to guide our application in the right direction.\n",
        "\n",
        "In this notebook, we're going to rely on the idea of \"zero-shot in-context learning\".\n",
        "\n",
        "This is a lot of words to say: \"We will ask it to perform our desired task in the prompt, and provide no examples.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXpA0UveR6yw"
      },
      "source": [
        "### XYZRolePrompt\n",
        "\n",
        "Before we do that, let's stop and think a bit about how OpenAI's chat models work.\n",
        "\n",
        "We know they have roles - as is indicated in the following API [documentation](https://platform.openai.com/docs/api-reference/chat/create#chat/create-messages)\n",
        "\n",
        "There are three roles, and they function as follows (taken directly from [OpenAI](https://platform.openai.com/docs/guides/gpt/chat-completions-api)):\n",
        "\n",
        "- `{\"role\" : \"system\"}` : The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. However note that the system message is optional and the model‚Äôs behavior without a system message is likely to be similar to using a generic message such as \"You are a helpful assistant.\"\n",
        "- `{\"role\" : \"user\"}` : The user messages provide requests or comments for the assistant to respond to.\n",
        "- `{\"role\" : \"assistant\"}` : Assistant messages store previous assistant responses, but can also be written by you to give examples of desired behavior.\n",
        "\n",
        "The main idea is this:\n",
        "\n",
        "1. You start with a system message that outlines how the LLM should respond, what kind of behaviours you can expect from it, and more\n",
        "2. Then, you can provide a few examples in the form of \"assistant\"/\"user\" pairs\n",
        "3. Then, you prompt the model with the true \"user\" message.\n",
        "\n",
        "In this example, we'll be forgoing the 2nd step for simplicities sake."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdZ2KWKSR6yw"
      },
      "source": [
        "#### Utility Functions\n",
        "\n",
        "You'll notice that we're using some utility functions from the `aimakerspace` module - let's take a peek at these and see what they're doing!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFbeJDDsR6yw"
      },
      "source": [
        "##### XYZRolePrompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mojJSE3R6yw"
      },
      "source": [
        "Here we have our `system`, `user`, and `assistant` role prompts.\n",
        "\n",
        "Let's take a peek at what they look like:\n",
        "\n",
        "```python\n",
        "class BasePrompt:\n",
        "    def __init__(self, prompt):\n",
        "        \"\"\"\n",
        "        Initializes the BasePrompt object with a prompt template.\n",
        "\n",
        "        :param prompt: A string that can contain placeholders within curly braces\n",
        "        \"\"\"\n",
        "        self.prompt = prompt\n",
        "        self._pattern = re.compile(r\"\\{([^}]+)\\}\")\n",
        "\n",
        "    def format_prompt(self, **kwargs):\n",
        "        \"\"\"\n",
        "        Formats the prompt string using the keyword arguments provided.\n",
        "\n",
        "        :param kwargs: The values to substitute into the prompt string\n",
        "        :return: The formatted prompt string\n",
        "        \"\"\"\n",
        "        matches = self._pattern.findall(self.prompt)\n",
        "        return self.prompt.format(**{match: kwargs.get(match, \"\") for match in matches})\n",
        "\n",
        "    def get_input_variables(self):\n",
        "        \"\"\"\n",
        "        Gets the list of input variable names from the prompt string.\n",
        "\n",
        "        :return: List of input variable names\n",
        "        \"\"\"\n",
        "        return self._pattern.findall(self.prompt)\n",
        "```\n",
        "\n",
        "Then we have our `RolePrompt` which laser focuses us on the role pattern found in most API endpoints for LLMs.\n",
        "\n",
        "```python\n",
        "class RolePrompt(BasePrompt):\n",
        "    def __init__(self, prompt, role: str):\n",
        "        \"\"\"\n",
        "        Initializes the RolePrompt object with a prompt template and a role.\n",
        "\n",
        "        :param prompt: A string that can contain placeholders within curly braces\n",
        "        :param role: The role for the message ('system', 'user', or 'assistant')\n",
        "        \"\"\"\n",
        "        super().__init__(prompt)\n",
        "        self.role = role\n",
        "\n",
        "    def create_message(self, **kwargs):\n",
        "        \"\"\"\n",
        "        Creates a message dictionary with a role and a formatted message.\n",
        "\n",
        "        :param kwargs: The values to substitute into the prompt string\n",
        "        :return: Dictionary containing the role and the formatted message\n",
        "        \"\"\"\n",
        "        return {\"role\": self.role, \"content\": self.format_prompt(**kwargs)}\n",
        "```\n",
        "\n",
        "We'll look at how the `SystemRolePrompt` is constructed to get a better idea of how that extension works:\n",
        "\n",
        "```python\n",
        "class SystemRolePrompt(RolePrompt):\n",
        "    def __init__(self, prompt: str):\n",
        "        super().__init__(prompt, \"system\")\n",
        "```\n",
        "\n",
        "That pattern is repeated for our `UserRolePrompt` and our `AssistantRolePrompt` as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D361R6sMR6yw"
      },
      "source": [
        "##### ChatOpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJVQ2Pm8R6yw"
      },
      "source": [
        "Next we have our model, which is converted to a format analagous to libraries like LangChain and LlamaIndex.\n",
        "\n",
        "Let's take a peek at how that is constructed:\n",
        "\n",
        "```python\n",
        "class ChatOpenAI:\n",
        "    def __init__(self, model_name: str = \"gpt-4o-mini\"):\n",
        "        self.model_name = model_name\n",
        "        self.openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "        if self.openai_api_key is None:\n",
        "            raise ValueError(\"OPENAI_API_KEY is not set\")\n",
        "\n",
        "    def run(self, messages, text_only: bool = True):\n",
        "        if not isinstance(messages, list):\n",
        "            raise ValueError(\"messages must be a list\")\n",
        "\n",
        "        openai.api_key = self.openai_api_key\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=self.model_name, messages=messages\n",
        "        )\n",
        "\n",
        "        if text_only:\n",
        "            return response.choices[0].message.content\n",
        "\n",
        "        return response\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCU7FfhIR6yw"
      },
      "source": [
        "#### ‚ùì Question #3:\n",
        "\n",
        "When calling the OpenAI API - are there any ways we can achieve more reproducible outputs?\n",
        "\n",
        "Yes we should set the temperatute of the model low in order to get more deterministic results.\n",
        "\n",
        "> NOTE: Check out [this section](https://platform.openai.com/docs/guides/text-generation/) of the OpenAI documentation for the answer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5wcjMLCR6yw"
      },
      "source": [
        "### Creating and Prompting OpenAI's `gpt-4o-mini`!\n",
        "\n",
        "Let's tie all these together and use it to prompt `gpt-4o-mini`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WIfpIot7R6yw"
      },
      "outputs": [],
      "source": [
        "from aimakerspace.openai_utils.prompts import (\n",
        "    UserRolePrompt,\n",
        "    SystemRolePrompt,\n",
        "    AssistantRolePrompt,\n",
        ")\n",
        "\n",
        "from aimakerspace.openai_utils.chatmodel import ChatOpenAI\n",
        "\n",
        "chat_openai = ChatOpenAI()\n",
        "user_prompt_template = \"{content}\"\n",
        "user_role_prompt = UserRolePrompt(user_prompt_template)\n",
        "system_prompt_template = (\n",
        "    \"You are an expert in {expertise}, you always answer in a kind way.\"\n",
        ")\n",
        "system_role_prompt = SystemRolePrompt(system_prompt_template)\n",
        "\n",
        "messages = [\n",
        "    system_role_prompt.create_message(expertise=\"Python\"),\n",
        "    user_role_prompt.create_message(\n",
        "        content=\"What is Automated Design of Agentic Systems?\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "response = chat_openai.run(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHo7lssNR6yw",
        "outputId": "1d3823fa-bb6b-45f6-ddba-b41686388324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Automated Design of Agentic Systems refers to the process of using automated tools and techniques to create systems that can operate autonomously, exhibiting behaviors typically associated with agents, such as decision-making, learning, and problem-solving. These systems are designed to perform tasks without direct human intervention, often utilizing advanced algorithms, artificial intelligence, and machine learning.\n",
            "\n",
            "In this context, \"agentic\" implies that the systems have some level of agency or self-governance, allowing them to make choices based on their environments, goals, and learning experiences. This could apply to various domains, including robotics, autonomous vehicles, smart systems, and software agents that interact with users or other systems.\n",
            "\n",
            "Key components in the automated design of agentic systems might include:\n",
            "\n",
            "1. **Modeling and Simulation**: Creating models of how agents will behave in various scenarios to test and refine their decision-making processes.\n",
            "  \n",
            "2. **Machine Learning**: Integrating algorithms that allow the system to learn from experiences and adapt to changing conditions.\n",
            "\n",
            "3. **Optimization**: Utilizing optimization techniques to enhance performance based on predefined criteria or objectives.\n",
            "\n",
            "4. **Autonomy**: Crafting systems that can independently accomplish tasks, often by incorporating feedback loops from their environment.\n",
            "\n",
            "5. **Interoperability**: Ensuring that different agents can interact effectively with each other and with humans or external systems.\n",
            "\n",
            "Automating the design process can lead to faster development cycles, more efficient design iterations, and potentially create systems that can handle complex environments and tasks more successfully than traditionally designed systems. \n",
            "\n",
            "If you have any more questions or need clarification on specific aspects, feel free to ask!\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2nxxhB2R6yy"
      },
      "source": [
        "## Task 5: Retrieval Augmented Generation\n",
        "\n",
        "Now we can create a RAG prompt - which will help our system behave in a way that makes sense!\n",
        "\n",
        "There is much you could do here, many tweaks and improvements to be made!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "D1hamzGaR6yy"
      },
      "outputs": [],
      "source": [
        "RAG_PROMPT_TEMPLATE = \"\"\" \\\n",
        "Use the provided context to answer the user's query.\n",
        "\n",
        "You may not answer the user's query unless there is specific context in the following text.\n",
        "\n",
        "If you do not know the answer, or cannot answer, please respond with \"I don't know\".\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = SystemRolePrompt(RAG_PROMPT_TEMPLATE)\n",
        "\n",
        "USER_PROMPT_TEMPLATE = \"\"\" \\\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "User Query:\n",
        "{user_query}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "user_prompt = UserRolePrompt(USER_PROMPT_TEMPLATE)\n",
        "\n",
        "class RetrievalAugmentedQAPipeline:\n",
        "    def __init__(self, llm: ChatOpenAI(), vector_db_retriever: VectorDatabase) -> None:\n",
        "        self.llm = llm\n",
        "        self.vector_db_retriever = vector_db_retriever\n",
        "\n",
        "    def run_pipeline(self, user_query: str) -> str:\n",
        "        context_list = self.vector_db_retriever.search_by_text(user_query, k=4)\n",
        "\n",
        "        context_prompt = \"\"\n",
        "        for context in context_list:\n",
        "            context_prompt += context[0] + \"\\n\"\n",
        "\n",
        "        formatted_system_prompt = rag_prompt.create_message()\n",
        "\n",
        "        formatted_user_prompt = user_prompt.create_message(user_query=user_query, context=context_prompt)\n",
        "\n",
        "        return {\"response\" : self.llm.run([formatted_system_prompt, formatted_user_prompt]), \"context\" : context_list}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZIJI19uR6yz"
      },
      "source": [
        "#### ‚ùì Question #4:\n",
        "\n",
        "What prompting strategies could you use to make the LLM have a more thoughtful, detailed response?\n",
        "\n",
        "I will use a stept by step approach in order to set the task clearly.\n",
        "\n",
        "What is that strategy called?\n",
        "\n",
        "Chain of thoughts\n",
        "\n",
        "> NOTE: You can look through the Week 1 Day 1 \"Prompting OpenAI Like A Developer\" material for an answer to this question!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kqbE9fZ6R6yz"
      },
      "outputs": [],
      "source": [
        "retrieval_augmented_qa_pipeline = RetrievalAugmentedQAPipeline(\n",
        "    vector_db_retriever=vector_db,\n",
        "    llm=chat_openai\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAGhaCGOR6yz",
        "outputId": "e4fb3a1b-d2bc-4e18-ec31-dc0adf767163"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'response': 'Automated Design of Agentic Systems (ADAS) is a research area aimed at automatically creating powerful agentic system designs. This involves inventing novel building blocks and/or combining existing ones in new ways. The approach uses a search algorithm to discover agentic systems across a defined search space, optimizing an evaluation function that measures performance on target objectives. ADAS is proposed as a means to accelerate the development of general-purpose agents, potentially allowing learned agents to outperform those that are hand-designed.',\n",
              " 'context': [('2024-8-19\\nAutomated Design of Agentic Systems\\nShengran Hu1,2, Cong Lu1,2and Jeff Clune1,2,3\\n1University of British Columbia,2Vector Institute,3Canada CIFAR AI Chair\\nResearchers are investing substantial effort in developing powerful general-purpose agents, wherein\\nFoundation Models are used as modules within agentic systems (e.g. Chain-of-Thought, Self-Reflection,\\nToolformer). However, the history of machine learning teaches us that hand-designed solutions are\\neventually replaced by learned solutions. We formulate a new research area, Automated Design of\\nAgentic Systems (ADAS), which aims to automatically create powerful agentic system designs, including\\ninventing novel building blocks and/or combining them in new ways. We further demonstrate that there\\nis an unexplored yet promising approach within ADAS where agents can be defined in code and new\\nagents can be automatically discovered by a meta agent programming ever better ones in code. Given\\nthat programming languages are Turing Com',\n",
              "   0.7458694515367679),\n",
              "  ('\\nAutomated Design of Agentic Systems\\nSearch Space\\nE.g. Agents defined by code\\nSearch Algorithm\\nE.g. LLM defines agents using code\\nEvaluation Function\\nE.g. Accuracy on the taskWhere is the capital of CanadaOttawa\\n‚úÖSampleNew AgentEvaluate the ObjectivesAgent‚Ä¶‚Ä¶1 + 1 = ?\\nFigure 2|The three key components of Automated Design of Agentic Systems (ADAS). The search\\nspace determines which agentic systems can be represented in ADAS. The search algorithm specifies\\nhow the ADAS method explores the search space. The evaluation function defines how to evaluate a\\ncandidate agent on target objectives such as performance.\\nFormulation\\nAutomated Design of Agentic Systems (ADAS) involves using a search algorithm to discover\\nagentic systems across a search space thatoptimize anevaluation function .\\n‚Ä¢Search Space : The search space defines which agentic systems can be represented and thus\\ndiscovered in ADAS. For example, works like PromptBreeder (Fernando et al., 2024) mutate only\\nthe text prompts of an age',\n",
              "   0.7208127039336015),\n",
              "  ('ing from\\nhuman organization and society. The agentic system is a machine learning system that operates\\nprimarily over natural language‚Äîa representation that is interpretable to humans and used by\\nhumans in constructing our organization and society. Thus, there is a close connection between\\nagentic systems and human organizations, as shown in works incorporating the organizational\\nstructure for human companies in agents (Hong et al., 2023) or simulating a human town with\\nagents (Park et al., 2023). Therefore, the study in ADAS may enable us to observe how to create\\na simple set of conditions and have an algorithm to bootstrap itself from simplicity to produce\\ncomplexity in a system akin to human society.\\n13\\nAutomated Design of Agentic Systems\\n‚Ä¢Towards a Better Understanding of FMs. Works from Neural Architecture Search (Huang et al.,\\n2023) show that by observing the emerged architecture, we could gain more insights into Neural\\nNetworks. In this paper, we also gained insights about FMs f',\n",
              "   0.717050003438478),\n",
              "  ('; and\\nan endless number of robotics learning environments can be automatically generated in works like\\nOMNI-EPIC (Faldor et al., 2024), which demonstrate surprising creativity in generated environments\\nand allow more efficient environment creation than the manual approach (see more examples in\\nSection 5). Therefore, in this paper, we propose a new research question: Can we automate the design\\nof agentic systems rather than relying on manual efforts?\\nTo explore the above research question, we formulate a new research area we call Automated\\nDesign of AgenticSystems (ADAS), which aims to automatically invent novel building blocks and\\ndesign powerful agentic systems (Section 2). We argue that ADAS may prove to be the fastest path to\\ndeveloping powerful agents, and show initial evidence that learned agents can greatly outperform\\nhand-designed agents. Considering the tremendous number of building blocks yet to be discovered in\\nagentic systems (Section 5), it would take a long time for our re',\n",
              "   0.7169899519188537)]}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieval_augmented_qa_pipeline.run_pipeline(\"What is Automated Design of Agentic Systems?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üèóÔ∏è Activity #1:\n",
        "\n",
        "Enhance your RAG application in some way! \n",
        "\n",
        "Suggestions are: \n",
        "\n",
        "- Allow it to work with PDF files\n",
        "- Implement a new distance metric\n",
        "- Add metadata support to the vector database\n",
        "\n",
        "While these are suggestions, you should feel free to make whatever augmentations you desire! \n",
        "\n",
        "> NOTE: These additions might require you to work within the `aimakerspace` library - that's expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "#1 Allow it to work with PDF files\n",
        "class PdFileLoader:\n",
        "    \"\"\"\n",
        "    Class to load and extract text from PDF files. Supports loading from a single PDF file or all PDF files within a directory.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, path: str):\n",
        "        self._documents = []\n",
        "        self.path = path\n",
        "\n",
        "    def load_pdf(self):\n",
        "        \"\"\"\n",
        "        Load text from a single PDF file specified by the path.\n",
        "        If the path is a directory, it will call the load_directory method.\n",
        "        \"\"\"\n",
        "        if os.path.isdir(self.path):\n",
        "            self.load_directory()\n",
        "        elif os.path.isfile(self.path):\n",
        "            self._load_single_pdf(self.path)\n",
        "        else:\n",
        "            raise ValueError(\"Provided path is neither a valid directory nor a valid PDF file\")\n",
        "\n",
        "    def _load_single_pdf(self, file_path):\n",
        "        \"\"\"\n",
        "        Helper method to load and extract text from a single PDF file.\n",
        "        \"\"\"\n",
        "        with open(file_path, \"rb\") as file:\n",
        "            try:\n",
        "                reader = PyPDF2.PdfReader(file)\n",
        "                text_parts = []\n",
        "                \n",
        "                for p in range(len(reader.pages)):\n",
        "                    page = reader.pages[p]\n",
        "                    text_parts.append(page.extract_text())\n",
        "                \n",
        "                document_text = \"\\n\".join(text_parts) if text_parts else \"<empty file>\"\n",
        "                self._documents.append(document_text)\n",
        "            \n",
        "            except PyPDF2.errors.PdfReadError as e:\n",
        "                raise ValueError(f\"Error reading the PDF file: {e}\")\n",
        "            except Exception as e:\n",
        "                raise ValueError(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "    def load_directory(self):\n",
        "        \"\"\"\n",
        "        Load and extract text from all PDF files within the specified directory.\n",
        "        \"\"\"\n",
        "        for root, _, files in os.walk(self.path):\n",
        "            for file in files:\n",
        "                if file.endswith(\".pdf\"):\n",
        "                    file_path = os.path.join(root, file)\n",
        "                    self._load_single_pdf(file_path)\n",
        "\n",
        "    def load_documents(self):\n",
        "        \"\"\"\n",
        "        Load documents from the specified path (either a file or a directory) and return the extracted text.\n",
        "        \"\"\"\n",
        "        self.load_pdf()\n",
        "        return self._documents\n",
        "    \n",
        "    \n",
        "#2 mesurement method\n",
        "\n",
        "import numpy as np\n",
        "def euclidean_distance(vector_a: np.array, vector_b: np.array) -> float:\n",
        "    \"\"\"Computes the Euclidean distance between two vectors.\"\"\"\n",
        "    return np.linalg.norm(vector_a - vector_b)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "buildyourownlangchain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ce393d9afcf427d9d352259c5d32678": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e6efd99f7d346e485b002fb0fa85cc7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3dfb67c39958461da6071e4c19c3fa41",
            "value": 1
          }
        },
        "3a4ba348cb004f8ab7b2b1395539c81b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2ea5009dd16442cb5d8a0ac468e50a8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5f00135fe1044051a50ee5e841cbb8e3",
            "value": "0.018 MB of 0.018 MB uploaded\r"
          }
        },
        "3dfb67c39958461da6071e4c19c3fa41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e6efd99f7d346e485b002fb0fa85cc7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56a8e24025594e5e9ff3b8581c344691": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f00135fe1044051a50ee5e841cbb8e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb904e05ece143c79ecc4f20de482f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a4ba348cb004f8ab7b2b1395539c81b",
              "IPY_MODEL_1ce393d9afcf427d9d352259c5d32678"
            ],
            "layout": "IPY_MODEL_56a8e24025594e5e9ff3b8581c344691"
          }
        },
        "d2ea5009dd16442cb5d8a0ac468e50a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
